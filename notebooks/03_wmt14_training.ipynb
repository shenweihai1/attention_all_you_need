{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# WMT14 English-German Training\n",
    "\n",
    "Production training notebook for the Transformer base model on WMT14 English-German translation task.\n",
    "\n",
    "## Configuration\n",
    "- **Model**: Base Transformer (d_model=512, n_heads=8, n_layers=6, d_ff=2048)\n",
    "- **Dataset**: WMT14 English-German (~4.5M sentence pairs)\n",
    "- **Tokenizer**: BPE with shared 37K vocabulary\n",
    "- **Training**: 100K steps, warmup 4000 steps, label smoothing 0.1\n",
    "\n",
    "## Requirements\n",
    "```bash\n",
    "pip install datasets sentencepiece sacrebleu\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5090\n",
      "Memory: 33.7 GB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Our implementation\n",
    "from src import Transformer\n",
    "from src.tokenizer import Tokenizer, PAD_ID, BOS_ID, EOS_ID\n",
    "from src.data import (\n",
    "    TranslationDataset,\n",
    "    TranslationCollator,\n",
    "    create_dynamic_dataloader,\n",
    "    DynamicBatchSampler,\n",
    ")\n",
    "from src.scheduler import TransformerScheduler\n",
    "from src.label_smoothing import LabelSmoothingLoss\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  d_model: 512\n",
      "  n_heads: 8\n",
      "  n_layers: 6\n",
      "  d_ff: 2048\n",
      "  dropout: 0.1\n",
      "  max_seq_len: 512\n",
      "  vocab_size: 37000\n",
      "  max_steps: 100000\n",
      "  warmup_steps: 4000\n",
      "  label_smoothing: 0.1\n",
      "  max_tokens_per_batch: 4096\n",
      "  gradient_accumulation_steps: 4\n",
      "  max_grad_norm: 1.0\n",
      "  adam_betas: (0.9, 0.98)\n",
      "  adam_eps: 1e-09\n",
      "  log_steps: 100\n",
      "  eval_steps: 2000\n",
      "  save_steps: 5000\n",
      "  checkpoint_dir: ../checkpoints/wmt14_base\n",
      "  max_train_samples: None\n",
      "  max_val_samples: 3000\n",
      "  num_workers: 4\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Modify these settings as needed\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Model (Base Transformer from the paper)\n",
    "    \"d_model\": 512,\n",
    "    \"n_heads\": 8,\n",
    "    \"n_layers\": 6,\n",
    "    \"d_ff\": 2048,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_seq_len\": 512,\n",
    "    \n",
    "    # Tokenizer\n",
    "    \"vocab_size\": 37000,  # Shared EN-DE vocabulary\n",
    "    \n",
    "    # Training\n",
    "    \"max_steps\": 100000,\n",
    "    \"warmup_steps\": 4000,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"max_tokens_per_batch\": 4096,  # Tokens per batch (dynamic batching)\n",
    "    \"gradient_accumulation_steps\": 4,  # Effective batch ~16K tokens\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \n",
    "    # Optimizer (Adam with paper settings)\n",
    "    \"adam_betas\": (0.9, 0.98),\n",
    "    \"adam_eps\": 1e-9,\n",
    "    \n",
    "    # Logging and checkpointing\n",
    "    \"log_steps\": 100,\n",
    "    \"eval_steps\": 2000,\n",
    "    \"save_steps\": 5000,\n",
    "    \"checkpoint_dir\": \"../checkpoints/wmt14_base\",\n",
    "    \n",
    "    # Data\n",
    "    \"max_train_samples\": None,  # Set to int for debugging (e.g., 10000)\n",
    "    \"max_val_samples\": 3000,    # Validation subset for speed\n",
    "    \"num_workers\": 4,\n",
    "}\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(CONFIG[\"checkpoint_dir\"], exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Load WMT14 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WMT14 English-German dataset...\n",
      "This may take a while on first run (downloading ~1.7GB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14365fccab4c4dc9882a2c546dd556c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4828945d416411db7dac915ab3d0226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "de-en/train-00000-of-00003.parquet:   0%|          | 0.00/280M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f858e3750d841ba9d49c6ab677e0829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "de-en/train-00001-of-00003.parquet:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006bc0a8e6ff42f3ba6dd3e60b234617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "de-en/train-00002-of-00003.parquet:   0%|          | 0.00/273M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2dca770557424999ae9cdb4b18fd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "de-en/validation-00000-of-00001.parquet:   0%|          | 0.00/474k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a17c5466ac2466f862aed83dc13d467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "de-en/test-00000-of-00001.parquet:   0%|          | 0.00/509k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66017b6fe3654930b4e8ea0c9a0d4eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4508785 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0689cac75c1b4b5097fabb0005b40433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a22af7a2604ab0b39f2d6960931e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset splits:\n",
      "  train: 4,508,785 examples\n",
      "  validation: 3,000 examples\n",
      "  test: 3,003 examples\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading WMT14 English-German dataset...\")\n",
    "print(\"This may take a while on first run (downloading ~1.7GB)\")\n",
    "\n",
    "# Load dataset\n",
    "wmt14 = load_dataset(\"wmt14\", \"de-en\")\n",
    "\n",
    "print(f\"\\nDataset splits:\")\n",
    "for split, data in wmt14.items():\n",
    "    print(f\"  {split}: {len(data):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting training sentences...\n",
      "Training: 4,508,785 sentence pairs\n",
      "Extracting validation sentences...\n",
      "Validation: 3,000 sentence pairs\n",
      "\n",
      "Example sentence pairs:\n",
      "\n",
      "  [1] EN: Resumption of the session\n",
      "      DE: Wiederaufnahme der Sitzungsperiode\n",
      "\n",
      "  [2] EN: I declare resumed the session of the European Parliament adjourned on Friday 17 ...\n",
      "      DE: Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des E...\n",
      "\n",
      "  [3] EN: Although, as you will have seen, the dreaded 'millennium bug' failed to material...\n",
      "      DE: Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetre...\n"
     ]
    }
   ],
   "source": [
    "# Extract sentences\n",
    "def extract_sentences(dataset, max_samples=None):\n",
    "    \"\"\"Extract EN and DE sentences from WMT dataset.\"\"\"\n",
    "    en_sentences = []\n",
    "    de_sentences = []\n",
    "    \n",
    "    for i, example in enumerate(dataset):\n",
    "        if max_samples and i >= max_samples:\n",
    "            break\n",
    "        translation = example[\"translation\"]\n",
    "        en_sentences.append(translation[\"en\"])\n",
    "        de_sentences.append(translation[\"de\"])\n",
    "    \n",
    "    return en_sentences, de_sentences\n",
    "\n",
    "# Extract training data\n",
    "print(\"Extracting training sentences...\")\n",
    "train_en, train_de = extract_sentences(\n",
    "    wmt14[\"train\"], \n",
    "    max_samples=CONFIG[\"max_train_samples\"]\n",
    ")\n",
    "print(f\"Training: {len(train_en):,} sentence pairs\")\n",
    "\n",
    "# Extract validation data\n",
    "print(\"Extracting validation sentences...\")\n",
    "val_en, val_de = extract_sentences(\n",
    "    wmt14[\"validation\"],\n",
    "    max_samples=CONFIG[\"max_val_samples\"]\n",
    ")\n",
    "print(f\"Validation: {len(val_en):,} sentence pairs\")\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nExample sentence pairs:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\n  [{i+1}] EN: {train_en[i][:80]}...\" if len(train_en[i]) > 80 else f\"\\n  [{i+1}] EN: {train_en[i]}\")\n",
    "    print(f\"      DE: {train_de[i][:80]}...\" if len(train_de[i]) > 80 else f\"      DE: {train_de[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Train BPE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing tokenizer from ../checkpoints/wmt14_base/tokenizer.model\n",
      "\n",
      "Tokenizer vocabulary size: 37000\n",
      "Special tokens: PAD=0, BOS=2, EOS=3\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "tokenizer_path = Path(CONFIG[\"checkpoint_dir\"]) / \"tokenizer.model\"\n",
    "\n",
    "if tokenizer_path.exists():\n",
    "    print(f\"Loading existing tokenizer from {tokenizer_path}\")\n",
    "    tokenizer = Tokenizer(model_path=str(tokenizer_path))\n",
    "else:\n",
    "    print(\"Training BPE tokenizer on combined EN+DE data...\")\n",
    "    print(f\"Target vocabulary size: {CONFIG['vocab_size']}\")\n",
    "\n",
    "    # Use smaller subset for tokenizer - 200K sentences is plenty for 37K vocab\n",
    "    tokenizer_train_size = min(200000, len(train_en))\n",
    "    print(f\"Using {tokenizer_train_size:,} sentence pairs (200K is sufficient for good BPE)\")\n",
    "   \n",
    "    # Write training data to temp file\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:\n",
    "        # Use subset for tokenizer training (faster)\n",
    "        # tokenizer_train_size = min(1000000, len(train_en))\n",
    "        for i in range(tokenizer_train_size):\n",
    "            f.write(train_en[i].strip() + \"\\n\")\n",
    "            f.write(train_de[i].strip() + \"\\n\")\n",
    "        temp_path = f.name\n",
    "    \n",
    "    print(f\"Training on {tokenizer_train_size * 2:,} sentences...\")\n",
    "    \n",
    "    # Train tokenizer\n",
    "    tokenizer = Tokenizer.train(\n",
    "        input_files=temp_path,\n",
    "        model_prefix=str(tokenizer_path).replace('.model', ''),\n",
    "        vocab_size=CONFIG[\"vocab_size\"],\n",
    "        model_type=\"bpe\",\n",
    "        character_coverage=1.0,\n",
    "        num_threads=8,\n",
    "    )\n",
    "    \n",
    "    # Cleanup\n",
    "    os.remove(temp_path)\n",
    "    print(f\"Tokenizer saved to {tokenizer_path}\")\n",
    "\n",
    "print(f\"\\nTokenizer vocabulary size: {tokenizer.vocab_size}\")\n",
    "print(f\"Special tokens: PAD={tokenizer.pad_id}, BOS={tokenizer.bos_id}, EOS={tokenizer.eos_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer test:\n",
      "\n",
      "  Input: The Transformer architecture is based on self-attention.\n",
      "  Pieces: ['▁The', '▁Trans', 'for', 'mer', '▁architecture', '▁is', '▁based', '▁on', '▁self', '-']...\n",
      "  IDs: [2, 251, 6473, 231, 501, 25882, 64, 2742, 128, 5374]... (len=15)\n",
      "  Decoded: The Transformer architecture is based on self-attention.\n",
      "\n",
      "  Input: Die Transformer-Architektur basiert auf Self-Attention.\n",
      "  Pieces: ['▁Die', '▁Trans', 'for', 'mer', '-', 'Ar', 'ch', 'itektur', '▁basiert', '▁auf']...\n",
      "  IDs: [2, 331, 6473, 231, 501, 36786, 19182, 9, 25292, 13264]... (len=19)\n",
      "  Decoded: Die Transformer-Architektur basiert auf Self-Attention.\n"
     ]
    }
   ],
   "source": [
    "# Test tokenizer\n",
    "test_sentences = [\n",
    "    \"The Transformer architecture is based on self-attention.\",\n",
    "    \"Die Transformer-Architektur basiert auf Self-Attention.\",\n",
    "]\n",
    "\n",
    "print(\"Tokenizer test:\")\n",
    "for sent in test_sentences:\n",
    "    ids = tokenizer.encode(sent, add_bos=True, add_eos=True)\n",
    "    pieces = tokenizer.encode_as_pieces(sent)\n",
    "    decoded = tokenizer.decode(ids)\n",
    "    print(f\"\\n  Input: {sent}\")\n",
    "    print(f\"  Pieces: {pieces[:10]}{'...' if len(pieces) > 10 else ''}\")\n",
    "    print(f\"  IDs: {ids[:10]}{'...' if len(ids) > 10 else ''} (len={len(ids)})\")\n",
    "    print(f\"  Decoded: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training dataset...\n",
      "Training dataset: 4,508,785 examples\n",
      "Creating validation dataset...\n",
      "Validation dataset: 3,000 examples\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating training dataset...\")\n",
    "train_dataset = TranslationDataset(\n",
    "    src_data=train_en,\n",
    "    tgt_data=train_de,\n",
    "    src_tokenizer=tokenizer,\n",
    "    tgt_tokenizer=tokenizer,\n",
    "    max_length=CONFIG[\"max_seq_len\"],\n",
    "    add_bos=True,\n",
    "    add_eos=True,\n",
    ")\n",
    "print(f\"Training dataset: {len(train_dataset):,} examples\")\n",
    "\n",
    "print(\"Creating validation dataset...\")\n",
    "val_dataset = TranslationDataset(\n",
    "    src_data=val_en,\n",
    "    tgt_data=val_de,\n",
    "    src_tokenizer=tokenizer,\n",
    "    tgt_tokenizer=tokenizer,\n",
    "    max_length=CONFIG[\"max_seq_len\"],\n",
    "    add_bos=True,\n",
    "    add_eos=True,\n",
    ")\n",
    "print(f\"Validation dataset: {len(val_dataset):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataloaders with max_tokens=4096...\n",
      "Training batches: 45,718\n",
      "Validation batches: 29\n",
      "\n",
      "Sample batch:\n",
      "  src shape: torch.Size([128, 24])\n",
      "  tgt shape: torch.Size([128, 24])\n",
      "  tokens in batch: 6144\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders with dynamic batching\n",
    "print(f\"Creating dataloaders with max_tokens={CONFIG['max_tokens_per_batch']}...\")\n",
    "\n",
    "train_loader = create_dynamic_dataloader(\n",
    "    dataset=train_dataset,\n",
    "    max_tokens=CONFIG[\"max_tokens_per_batch\"],\n",
    "    max_sentences=128,\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG[\"num_workers\"],\n",
    "    pad_id=tokenizer.pad_id,\n",
    ")\n",
    "\n",
    "val_loader = create_dynamic_dataloader(\n",
    "    dataset=val_dataset,\n",
    "    max_tokens=CONFIG[\"max_tokens_per_batch\"],\n",
    "    max_sentences=128,\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG[\"num_workers\"],\n",
    "    pad_id=tokenizer.pad_id,\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader):,}\")\n",
    "print(f\"Validation batches: {len(val_loader):,}\")\n",
    "\n",
    "# Check first batch\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch:\")\n",
    "print(f\"  src shape: {sample_batch['src'].shape}\")\n",
    "print(f\"  tgt shape: {sample_batch['tgt'].shape}\")\n",
    "print(f\"  tokens in batch: {sample_batch['src'].numel() + sample_batch['tgt'].numel()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 5. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Transformer model...\n",
      "  d_model: 512\n",
      "  n_heads: 8\n",
      "  n_layers: 6\n",
      "  d_ff: 2048\n",
      "  vocab_size: 37000\n",
      "\n",
      "Model parameters:\n",
      "  Total: 82,028,680\n",
      "  Trainable: 82,028,680\n",
      "  Size: ~328.1 MB (fp32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Transformer model...\")\n",
    "print(f\"  d_model: {CONFIG['d_model']}\")\n",
    "print(f\"  n_heads: {CONFIG['n_heads']}\")\n",
    "print(f\"  n_layers: {CONFIG['n_layers']}\")\n",
    "print(f\"  d_ff: {CONFIG['d_ff']}\")\n",
    "print(f\"  vocab_size: {tokenizer.vocab_size}\")\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=tokenizer.vocab_size,\n",
    "    tgt_vocab_size=tokenizer.vocab_size,\n",
    "    d_model=CONFIG[\"d_model\"],\n",
    "    n_heads=CONFIG[\"n_heads\"],\n",
    "    n_encoder_layers=CONFIG[\"n_layers\"],\n",
    "    n_decoder_layers=CONFIG[\"n_layers\"],\n",
    "    d_ff=CONFIG[\"d_ff\"],\n",
    "    dropout=CONFIG[\"dropout\"],\n",
    "    max_seq_len=CONFIG[\"max_seq_len\"],\n",
    "    pad_idx=tokenizer.pad_id,\n",
    "    share_embeddings=True,  # Share embeddings between encoder and decoder\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")\n",
    "print(f\"  Size: ~{total_params * 4 / 1e6:.1f} MB (fp32)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing forward pass...\n",
      "  Input src: torch.Size([128, 24])\n",
      "  Input tgt: torch.Size([128, 23])\n",
      "  Output logits: torch.Size([128, 23, 37000])\n",
      "  Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# Test forward pass\n",
    "print(\"Testing forward pass...\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    src = sample_batch['src'].to(device)\n",
    "    tgt = sample_batch['tgt'].to(device)\n",
    "    tgt_input = tgt[:, :-1]\n",
    "    \n",
    "    logits = model(src, tgt_input)\n",
    "    print(f\"  Input src: {src.shape}\")\n",
    "    print(f\"  Input tgt: {tgt_input.shape}\")\n",
    "    print(f\"  Output logits: {logits.shape}\")\n",
    "    print(f\"  Forward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 6. Setup Training Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training components:\n",
      "  Optimizer: Adam (betas=(0.9, 0.98), eps=1e-09)\n",
      "  Scheduler: Transformer LR (warmup=4000 steps)\n",
      "  Loss: Label smoothing (eps=0.1)\n",
      "  Gradient accumulation: 4 steps\n",
      "  Max gradient norm: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1.0,  # Will be controlled by scheduler\n",
    "    betas=CONFIG[\"adam_betas\"],\n",
    "    eps=CONFIG[\"adam_eps\"],\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = TransformerScheduler(\n",
    "    optimizer,\n",
    "    d_model=CONFIG[\"d_model\"],\n",
    "    warmup_steps=CONFIG[\"warmup_steps\"],\n",
    ")\n",
    "\n",
    "# Loss function with label smoothing\n",
    "criterion = LabelSmoothingLoss(\n",
    "    smoothing=CONFIG[\"label_smoothing\"],\n",
    "    padding_idx=tokenizer.pad_id,\n",
    ")\n",
    "\n",
    "print(\"Training components:\")\n",
    "print(f\"  Optimizer: Adam (betas={CONFIG['adam_betas']}, eps={CONFIG['adam_eps']})\")\n",
    "print(f\"  Scheduler: Transformer LR (warmup={CONFIG['warmup_steps']} steps)\")\n",
    "print(f\"  Loss: Label smoothing (eps={CONFIG['label_smoothing']})\")\n",
    "print(f\"  Gradient accumulation: {CONFIG['gradient_accumulation_steps']} steps\")\n",
    "print(f\"  Max gradient norm: {CONFIG['max_grad_norm']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, criterion, device):\n",
    "    \"\"\"Single training step.\"\"\"\n",
    "    src = batch['src'].to(device)\n",
    "    tgt = batch['tgt'].to(device)\n",
    "    \n",
    "    # Teacher forcing: input is tgt[:-1], target is tgt[1:]\n",
    "    tgt_input = tgt[:, :-1]\n",
    "    tgt_output = tgt[:, 1:]\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(src, tgt_input)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(\n",
    "        logits.contiguous().view(-1, logits.size(-1)),\n",
    "        tgt_output.contiguous().view(-1)\n",
    "    )\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader, criterion, device, max_batches=None):\n",
    "    \"\"\"Evaluate model on validation set.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for i, batch in enumerate(val_loader):\n",
    "        if max_batches and i >= max_batches:\n",
    "            break\n",
    "            \n",
    "        src = batch['src'].to(device)\n",
    "        tgt = batch['tgt'].to(device)\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        \n",
    "        logits = model(src, tgt_input)\n",
    "        loss = criterion(\n",
    "            logits.contiguous().view(-1, logits.size(-1)),\n",
    "            tgt_output.contiguous().view(-1)\n",
    "        )\n",
    "        \n",
    "        # Count non-padding tokens\n",
    "        non_pad = (tgt_output != tokenizer.pad_id).sum().item()\n",
    "        total_loss += loss.item() * non_pad\n",
    "        total_tokens += non_pad\n",
    "    \n",
    "    model.train()\n",
    "    return total_loss / total_tokens if total_tokens > 0 else 0.0\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, scheduler, step, loss, path):\n",
    "    \"\"\"Save training checkpoint.\"\"\"\n",
    "    checkpoint = {\n",
    "        'step': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'loss': loss,\n",
    "        'config': CONFIG,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fresh training\n"
     ]
    }
   ],
   "source": [
    "# Training state\n",
    "global_step = 0\n",
    "best_val_loss = float('inf')\n",
    "training_history = []\n",
    "\n",
    "# Check for existing checkpoint to resume\n",
    "resume_path = Path(CONFIG[\"checkpoint_dir\"]) / \"latest_checkpoint.pt\"\n",
    "if resume_path.exists():\n",
    "    print(f\"Resuming from {resume_path}\")\n",
    "    checkpoint = torch.load(resume_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    global_step = checkpoint['step']\n",
    "    print(f\"Resumed from step {global_step}\")\n",
    "else:\n",
    "    print(\"Starting fresh training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Starting training for 100,000 steps\n",
      "Gradient accumulation: 4 steps\n",
      "Effective batch size: ~16,384 tokens\n",
      "======================================================================\n",
      "Step    100 | Loss: 9.9215 | LR: 1.76e-05 | Speed: 5.4 steps/s\n",
      "Step    200 | Loss: 8.8597 | LR: 3.51e-05 | Speed: 5.7 steps/s\n",
      "Step    300 | Loss: 8.0831 | LR: 5.26e-05 | Speed: 5.7 steps/s\n",
      "Step    400 | Loss: 7.7754 | LR: 7.01e-05 | Speed: 5.6 steps/s\n",
      "Step    500 | Loss: 7.9104 | LR: 8.75e-05 | Speed: 5.6 steps/s\n",
      "Step    600 | Loss: 7.3925 | LR: 1.05e-04 | Speed: 5.6 steps/s\n",
      "Step    700 | Loss: 7.1640 | LR: 1.22e-04 | Speed: 5.6 steps/s\n",
      "Step    800 | Loss: 7.3377 | LR: 1.40e-04 | Speed: 5.6 steps/s\n",
      "Step    900 | Loss: 7.1376 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step   1000 | Loss: 6.5987 | LR: 1.75e-04 | Speed: 5.6 steps/s\n",
      "Step   1100 | Loss: 6.6162 | LR: 1.92e-04 | Speed: 5.7 steps/s\n",
      "Step   1200 | Loss: 6.4070 | LR: 2.10e-04 | Speed: 5.6 steps/s\n",
      "Step   1300 | Loss: 6.4417 | LR: 2.27e-04 | Speed: 5.6 steps/s\n",
      "Step   1400 | Loss: 6.7531 | LR: 2.45e-04 | Speed: 5.6 steps/s\n",
      "Step   1500 | Loss: 6.2347 | LR: 2.62e-04 | Speed: 5.5 steps/s\n",
      "Step   1600 | Loss: 6.2322 | LR: 2.80e-04 | Speed: 5.6 steps/s\n",
      "Step   1700 | Loss: 6.2774 | LR: 2.97e-04 | Speed: 5.6 steps/s\n",
      "Step   1800 | Loss: 6.2529 | LR: 3.15e-04 | Speed: 5.7 steps/s\n",
      "Step   1900 | Loss: 6.0104 | LR: 3.32e-04 | Speed: 5.7 steps/s\n",
      "Step   2000 | Loss: 5.8357 | LR: 3.50e-04 | Speed: 5.5 steps/s\n",
      "  >> Validation loss: 6.2303\n",
      "  >> New best model saved!\n",
      "Step   2100 | Loss: 6.0152 | LR: 3.67e-04 | Speed: 4.5 steps/s\n",
      "Step   2200 | Loss: 5.7885 | LR: 3.84e-04 | Speed: 5.7 steps/s\n",
      "Step   2300 | Loss: 6.0277 | LR: 4.02e-04 | Speed: 5.6 steps/s\n",
      "Step   2400 | Loss: 6.0000 | LR: 4.19e-04 | Speed: 5.6 steps/s\n",
      "Step   2500 | Loss: 5.8088 | LR: 4.37e-04 | Speed: 5.7 steps/s\n",
      "Step   2600 | Loss: 5.9072 | LR: 4.54e-04 | Speed: 5.7 steps/s\n",
      "Step   2700 | Loss: 5.2553 | LR: 4.72e-04 | Speed: 5.6 steps/s\n",
      "Step   2800 | Loss: 5.4671 | LR: 4.89e-04 | Speed: 5.6 steps/s\n",
      "Step   2900 | Loss: 5.2193 | LR: 5.07e-04 | Speed: 5.7 steps/s\n",
      "Step   3000 | Loss: 5.4544 | LR: 5.24e-04 | Speed: 5.8 steps/s\n",
      "Step   3100 | Loss: 5.3605 | LR: 5.42e-04 | Speed: 5.7 steps/s\n",
      "Step   3200 | Loss: 5.2149 | LR: 5.59e-04 | Speed: 5.6 steps/s\n",
      "Step   3300 | Loss: 5.4276 | LR: 5.77e-04 | Speed: 5.6 steps/s\n",
      "Step   3400 | Loss: 5.1832 | LR: 5.94e-04 | Speed: 5.6 steps/s\n",
      "Step   3500 | Loss: 5.1280 | LR: 6.12e-04 | Speed: 5.6 steps/s\n",
      "Step   3600 | Loss: 5.3227 | LR: 6.29e-04 | Speed: 5.6 steps/s\n",
      "Step   3700 | Loss: 5.2034 | LR: 6.47e-04 | Speed: 5.6 steps/s\n",
      "Step   3800 | Loss: 4.8641 | LR: 6.64e-04 | Speed: 5.7 steps/s\n",
      "Step   3900 | Loss: 5.2128 | LR: 6.81e-04 | Speed: 5.6 steps/s\n",
      "Step   4000 | Loss: 4.7803 | LR: 6.99e-04 | Speed: 5.8 steps/s\n",
      "  >> Validation loss: 5.5079\n",
      "  >> New best model saved!\n",
      "Step   4100 | Loss: 5.8790 | LR: 6.90e-04 | Speed: 4.5 steps/s\n",
      "Step   4200 | Loss: 4.9952 | LR: 6.82e-04 | Speed: 5.5 steps/s\n",
      "Step   4300 | Loss: 5.2886 | LR: 6.74e-04 | Speed: 5.6 steps/s\n",
      "Step   4400 | Loss: 4.8902 | LR: 6.66e-04 | Speed: 5.6 steps/s\n",
      "Step   4500 | Loss: 4.7105 | LR: 6.59e-04 | Speed: 5.6 steps/s\n",
      "Step   4600 | Loss: 4.2955 | LR: 6.52e-04 | Speed: 5.6 steps/s\n",
      "Step   4700 | Loss: 4.4825 | LR: 6.45e-04 | Speed: 5.6 steps/s\n",
      "Step   4800 | Loss: 5.2108 | LR: 6.38e-04 | Speed: 5.7 steps/s\n",
      "Step   4900 | Loss: 5.1234 | LR: 6.31e-04 | Speed: 5.6 steps/s\n",
      "Step   5000 | Loss: 5.0175 | LR: 6.25e-04 | Speed: 5.6 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_5000.pt\n",
      "Step   5100 | Loss: 5.2867 | LR: 6.19e-04 | Speed: 4.2 steps/s\n",
      "Step   5200 | Loss: 5.1417 | LR: 6.13e-04 | Speed: 5.7 steps/s\n",
      "Step   5300 | Loss: 5.3326 | LR: 6.07e-04 | Speed: 5.8 steps/s\n",
      "Step   5400 | Loss: 4.6520 | LR: 6.01e-04 | Speed: 5.7 steps/s\n",
      "Step   5500 | Loss: 5.2303 | LR: 5.96e-04 | Speed: 5.7 steps/s\n",
      "Step   5600 | Loss: 4.6983 | LR: 5.91e-04 | Speed: 5.6 steps/s\n",
      "Step   5700 | Loss: 4.7781 | LR: 5.85e-04 | Speed: 5.7 steps/s\n",
      "Step   5800 | Loss: 4.8662 | LR: 5.80e-04 | Speed: 5.7 steps/s\n",
      "Step   5900 | Loss: 4.4770 | LR: 5.75e-04 | Speed: 5.7 steps/s\n",
      "Step   6000 | Loss: 5.2567 | LR: 5.70e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 5.1164\n",
      "  >> New best model saved!\n",
      "Step   6100 | Loss: 4.9559 | LR: 5.66e-04 | Speed: 4.4 steps/s\n",
      "Step   6200 | Loss: 5.1256 | LR: 5.61e-04 | Speed: 5.7 steps/s\n",
      "Step   6300 | Loss: 4.9593 | LR: 5.57e-04 | Speed: 5.6 steps/s\n",
      "Step   6400 | Loss: 4.6987 | LR: 5.52e-04 | Speed: 5.6 steps/s\n",
      "Step   6500 | Loss: 5.3368 | LR: 5.48e-04 | Speed: 5.6 steps/s\n",
      "Step   6600 | Loss: 5.0467 | LR: 5.44e-04 | Speed: 5.7 steps/s\n",
      "Step   6700 | Loss: 5.1480 | LR: 5.40e-04 | Speed: 5.6 steps/s\n",
      "Step   6800 | Loss: 4.4938 | LR: 5.36e-04 | Speed: 5.6 steps/s\n",
      "Step   6900 | Loss: 4.8298 | LR: 5.32e-04 | Speed: 5.5 steps/s\n",
      "Step   7000 | Loss: 4.3365 | LR: 5.28e-04 | Speed: 5.6 steps/s\n",
      "Step   7100 | Loss: 4.8877 | LR: 5.24e-04 | Speed: 5.6 steps/s\n",
      "Step   7200 | Loss: 5.0244 | LR: 5.21e-04 | Speed: 5.6 steps/s\n",
      "Step   7300 | Loss: 4.6890 | LR: 5.17e-04 | Speed: 5.6 steps/s\n",
      "Step   7400 | Loss: 4.7987 | LR: 5.14e-04 | Speed: 5.6 steps/s\n",
      "Step   7500 | Loss: 4.6532 | LR: 5.10e-04 | Speed: 5.6 steps/s\n",
      "Step   7600 | Loss: 4.4892 | LR: 5.07e-04 | Speed: 5.6 steps/s\n",
      "Step   7700 | Loss: 4.3116 | LR: 5.04e-04 | Speed: 5.7 steps/s\n",
      "Step   7800 | Loss: 4.7532 | LR: 5.00e-04 | Speed: 5.7 steps/s\n",
      "Step   7900 | Loss: 4.5069 | LR: 4.97e-04 | Speed: 5.7 steps/s\n",
      "Step   8000 | Loss: 4.4645 | LR: 4.94e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.9980\n",
      "  >> New best model saved!\n",
      "Step   8100 | Loss: 4.1454 | LR: 4.91e-04 | Speed: 4.5 steps/s\n",
      "Step   8200 | Loss: 4.8983 | LR: 4.88e-04 | Speed: 5.7 steps/s\n",
      "Step   8300 | Loss: 4.3607 | LR: 4.85e-04 | Speed: 5.6 steps/s\n",
      "Step   8400 | Loss: 4.3642 | LR: 4.82e-04 | Speed: 5.7 steps/s\n",
      "Step   8500 | Loss: 4.8339 | LR: 4.79e-04 | Speed: 5.6 steps/s\n",
      "Step   8600 | Loss: 5.3101 | LR: 4.77e-04 | Speed: 5.6 steps/s\n",
      "Step   8700 | Loss: 4.1242 | LR: 4.74e-04 | Speed: 5.7 steps/s\n",
      "Step   8800 | Loss: 4.2912 | LR: 4.71e-04 | Speed: 5.8 steps/s\n",
      "Step   8900 | Loss: 5.0118 | LR: 4.68e-04 | Speed: 5.7 steps/s\n",
      "Step   9000 | Loss: 4.0397 | LR: 4.66e-04 | Speed: 5.7 steps/s\n",
      "Step   9100 | Loss: 5.0274 | LR: 4.63e-04 | Speed: 5.7 steps/s\n",
      "Step   9200 | Loss: 4.3387 | LR: 4.61e-04 | Speed: 5.6 steps/s\n",
      "Step   9300 | Loss: 4.4405 | LR: 4.58e-04 | Speed: 5.7 steps/s\n",
      "Step   9400 | Loss: 4.3447 | LR: 4.56e-04 | Speed: 5.7 steps/s\n",
      "Step   9500 | Loss: 4.6100 | LR: 4.53e-04 | Speed: 5.7 steps/s\n",
      "Step   9600 | Loss: 4.5361 | LR: 4.51e-04 | Speed: 5.5 steps/s\n",
      "Step   9700 | Loss: 4.6035 | LR: 4.49e-04 | Speed: 5.6 steps/s\n",
      "Step   9800 | Loss: 5.0576 | LR: 4.46e-04 | Speed: 5.6 steps/s\n",
      "Step   9900 | Loss: 4.2010 | LR: 4.44e-04 | Speed: 5.7 steps/s\n",
      "Step  10000 | Loss: 4.1941 | LR: 4.42e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.9276\n",
      "  >> New best model saved!\n",
      "  >> Checkpoint saved: checkpoint_step_10000.pt\n",
      "Step  10100 | Loss: 4.7566 | LR: 4.40e-04 | Speed: 3.6 steps/s\n",
      "Step  10200 | Loss: 4.7160 | LR: 4.38e-04 | Speed: 5.7 steps/s\n",
      "Step  10300 | Loss: 4.9066 | LR: 4.35e-04 | Speed: 5.6 steps/s\n",
      "Step  10400 | Loss: 4.7835 | LR: 4.33e-04 | Speed: 5.7 steps/s\n",
      "Step  10500 | Loss: 4.8118 | LR: 4.31e-04 | Speed: 5.6 steps/s\n",
      "Step  10600 | Loss: 4.8777 | LR: 4.29e-04 | Speed: 5.6 steps/s\n",
      "Step  10700 | Loss: 4.4550 | LR: 4.27e-04 | Speed: 5.6 steps/s\n",
      "Step  10800 | Loss: 4.7444 | LR: 4.25e-04 | Speed: 5.6 steps/s\n",
      "Step  10900 | Loss: 4.5093 | LR: 4.23e-04 | Speed: 5.6 steps/s\n",
      "Step  11000 | Loss: 4.6305 | LR: 4.21e-04 | Speed: 5.6 steps/s\n",
      "Step  11100 | Loss: 4.1576 | LR: 4.19e-04 | Speed: 5.7 steps/s\n",
      "Step  11200 | Loss: 4.1419 | LR: 4.18e-04 | Speed: 5.6 steps/s\n",
      "Step  11300 | Loss: 4.1836 | LR: 4.16e-04 | Speed: 5.6 steps/s\n",
      "Step  11400 | Loss: 4.7357 | LR: 4.14e-04 | Speed: 5.6 steps/s\n",
      "\n",
      "--- Epoch 1 completed ---\n",
      "\n",
      "Step  11500 | Loss: 4.5272 | LR: 4.12e-04 | Speed: 5.3 steps/s\n",
      "Step  11600 | Loss: 4.4590 | LR: 4.10e-04 | Speed: 5.5 steps/s\n",
      "Step  11700 | Loss: 4.1370 | LR: 4.09e-04 | Speed: 5.6 steps/s\n",
      "Step  11800 | Loss: 4.6311 | LR: 4.07e-04 | Speed: 5.6 steps/s\n",
      "Step  11900 | Loss: 4.0009 | LR: 4.05e-04 | Speed: 5.6 steps/s\n",
      "Step  12000 | Loss: 4.0841 | LR: 4.03e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.8573\n",
      "  >> New best model saved!\n",
      "Step  12100 | Loss: 4.4046 | LR: 4.02e-04 | Speed: 4.5 steps/s\n",
      "Step  12200 | Loss: 4.6536 | LR: 4.00e-04 | Speed: 5.6 steps/s\n",
      "Step  12300 | Loss: 4.0369 | LR: 3.98e-04 | Speed: 5.7 steps/s\n",
      "Step  12400 | Loss: 4.3913 | LR: 3.97e-04 | Speed: 5.6 steps/s\n",
      "Step  12500 | Loss: 4.2100 | LR: 3.95e-04 | Speed: 5.6 steps/s\n",
      "Step  12600 | Loss: 4.4086 | LR: 3.94e-04 | Speed: 5.6 steps/s\n",
      "Step  12700 | Loss: 4.8183 | LR: 3.92e-04 | Speed: 5.6 steps/s\n",
      "Step  12800 | Loss: 4.3672 | LR: 3.91e-04 | Speed: 5.6 steps/s\n",
      "Step  12900 | Loss: 4.6140 | LR: 3.89e-04 | Speed: 5.6 steps/s\n",
      "Step  13000 | Loss: 4.7478 | LR: 3.88e-04 | Speed: 5.6 steps/s\n",
      "Step  13100 | Loss: 4.8965 | LR: 3.86e-04 | Speed: 5.6 steps/s\n",
      "Step  13200 | Loss: 4.2341 | LR: 3.85e-04 | Speed: 5.5 steps/s\n",
      "Step  13300 | Loss: 4.6852 | LR: 3.83e-04 | Speed: 5.7 steps/s\n",
      "Step  13400 | Loss: 4.0590 | LR: 3.82e-04 | Speed: 5.7 steps/s\n",
      "Step  13500 | Loss: 4.3435 | LR: 3.80e-04 | Speed: 5.7 steps/s\n",
      "Step  13600 | Loss: 4.8878 | LR: 3.79e-04 | Speed: 5.5 steps/s\n",
      "Step  13700 | Loss: 4.5123 | LR: 3.78e-04 | Speed: 5.6 steps/s\n",
      "Step  13800 | Loss: 4.4710 | LR: 3.76e-04 | Speed: 5.7 steps/s\n",
      "Step  13900 | Loss: 4.4195 | LR: 3.75e-04 | Speed: 5.6 steps/s\n",
      "Step  14000 | Loss: 4.8506 | LR: 3.73e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.8001\n",
      "  >> New best model saved!\n",
      "Step  14100 | Loss: 4.7084 | LR: 3.72e-04 | Speed: 4.5 steps/s\n",
      "Step  14200 | Loss: 3.9203 | LR: 3.71e-04 | Speed: 5.5 steps/s\n",
      "Step  14300 | Loss: 4.8042 | LR: 3.70e-04 | Speed: 5.5 steps/s\n",
      "Step  14400 | Loss: 4.3086 | LR: 3.68e-04 | Speed: 5.7 steps/s\n",
      "Step  14500 | Loss: 4.7386 | LR: 3.67e-04 | Speed: 5.6 steps/s\n",
      "Step  14600 | Loss: 4.8716 | LR: 3.66e-04 | Speed: 5.7 steps/s\n",
      "Step  14700 | Loss: 4.7589 | LR: 3.64e-04 | Speed: 5.8 steps/s\n",
      "Step  14800 | Loss: 4.7056 | LR: 3.63e-04 | Speed: 5.7 steps/s\n",
      "Step  14900 | Loss: 3.9926 | LR: 3.62e-04 | Speed: 5.7 steps/s\n",
      "Step  15000 | Loss: 4.3018 | LR: 3.61e-04 | Speed: 5.6 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_15000.pt\n",
      "Step  15100 | Loss: 3.9555 | LR: 3.60e-04 | Speed: 4.2 steps/s\n",
      "Step  15200 | Loss: 4.1906 | LR: 3.58e-04 | Speed: 5.7 steps/s\n",
      "Step  15300 | Loss: 4.2870 | LR: 3.57e-04 | Speed: 5.6 steps/s\n",
      "Step  15400 | Loss: 4.7250 | LR: 3.56e-04 | Speed: 5.7 steps/s\n",
      "Step  15500 | Loss: 4.0910 | LR: 3.55e-04 | Speed: 5.6 steps/s\n",
      "Step  15600 | Loss: 4.5381 | LR: 3.54e-04 | Speed: 5.6 steps/s\n",
      "Step  15700 | Loss: 4.2063 | LR: 3.53e-04 | Speed: 5.6 steps/s\n",
      "Step  15800 | Loss: 4.6332 | LR: 3.52e-04 | Speed: 5.6 steps/s\n",
      "Step  15900 | Loss: 4.6722 | LR: 3.50e-04 | Speed: 5.6 steps/s\n",
      "Step  16000 | Loss: 4.4460 | LR: 3.49e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.7658\n",
      "  >> New best model saved!\n",
      "Step  16100 | Loss: 4.1968 | LR: 3.48e-04 | Speed: 4.5 steps/s\n",
      "Step  16200 | Loss: 4.1964 | LR: 3.47e-04 | Speed: 5.6 steps/s\n",
      "Step  16300 | Loss: 4.5010 | LR: 3.46e-04 | Speed: 5.6 steps/s\n",
      "Step  16400 | Loss: 4.5747 | LR: 3.45e-04 | Speed: 5.6 steps/s\n",
      "Step  16500 | Loss: 4.5200 | LR: 3.44e-04 | Speed: 5.7 steps/s\n",
      "Step  16600 | Loss: 4.5221 | LR: 3.43e-04 | Speed: 5.7 steps/s\n",
      "Step  16700 | Loss: 4.3474 | LR: 3.42e-04 | Speed: 5.6 steps/s\n",
      "Step  16800 | Loss: 3.9762 | LR: 3.41e-04 | Speed: 5.6 steps/s\n",
      "Step  16900 | Loss: 4.3140 | LR: 3.40e-04 | Speed: 5.7 steps/s\n",
      "Step  17000 | Loss: 4.3087 | LR: 3.39e-04 | Speed: 5.6 steps/s\n",
      "Step  17100 | Loss: 4.3384 | LR: 3.38e-04 | Speed: 5.6 steps/s\n",
      "Step  17200 | Loss: 4.5339 | LR: 3.37e-04 | Speed: 5.6 steps/s\n",
      "Step  17300 | Loss: 4.5672 | LR: 3.36e-04 | Speed: 5.6 steps/s\n",
      "Step  17400 | Loss: 4.7316 | LR: 3.35e-04 | Speed: 5.6 steps/s\n",
      "Step  17500 | Loss: 4.3825 | LR: 3.34e-04 | Speed: 5.7 steps/s\n",
      "Step  17600 | Loss: 4.9804 | LR: 3.33e-04 | Speed: 5.6 steps/s\n",
      "Step  17700 | Loss: 4.4413 | LR: 3.32e-04 | Speed: 5.6 steps/s\n",
      "Step  17800 | Loss: 4.1716 | LR: 3.31e-04 | Speed: 5.6 steps/s\n",
      "Step  17900 | Loss: 4.9410 | LR: 3.30e-04 | Speed: 5.6 steps/s\n",
      "Step  18000 | Loss: 4.3476 | LR: 3.29e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.7691\n",
      "Step  18100 | Loss: 4.5476 | LR: 3.28e-04 | Speed: 5.3 steps/s\n",
      "Step  18200 | Loss: 3.8501 | LR: 3.28e-04 | Speed: 5.6 steps/s\n",
      "Step  18300 | Loss: 4.0839 | LR: 3.27e-04 | Speed: 5.7 steps/s\n",
      "Step  18400 | Loss: 4.4105 | LR: 3.26e-04 | Speed: 5.7 steps/s\n",
      "Step  18500 | Loss: 4.6973 | LR: 3.25e-04 | Speed: 5.5 steps/s\n",
      "Step  18600 | Loss: 4.2382 | LR: 3.24e-04 | Speed: 5.6 steps/s\n",
      "Step  18700 | Loss: 4.2620 | LR: 3.23e-04 | Speed: 5.6 steps/s\n",
      "Step  18800 | Loss: 4.3875 | LR: 3.22e-04 | Speed: 5.6 steps/s\n",
      "Step  18900 | Loss: 4.4399 | LR: 3.21e-04 | Speed: 5.6 steps/s\n",
      "Step  19000 | Loss: 3.7445 | LR: 3.21e-04 | Speed: 5.6 steps/s\n",
      "Step  19100 | Loss: 4.5286 | LR: 3.20e-04 | Speed: 5.6 steps/s\n",
      "Step  19200 | Loss: 4.8400 | LR: 3.19e-04 | Speed: 5.6 steps/s\n",
      "Step  19300 | Loss: 4.5038 | LR: 3.18e-04 | Speed: 5.6 steps/s\n",
      "Step  19400 | Loss: 4.4050 | LR: 3.17e-04 | Speed: 5.6 steps/s\n",
      "Step  19500 | Loss: 4.2895 | LR: 3.16e-04 | Speed: 5.5 steps/s\n",
      "Step  19600 | Loss: 4.5218 | LR: 3.16e-04 | Speed: 5.6 steps/s\n",
      "Step  19700 | Loss: 4.0017 | LR: 3.15e-04 | Speed: 5.6 steps/s\n",
      "Step  19800 | Loss: 4.1331 | LR: 3.14e-04 | Speed: 5.6 steps/s\n",
      "Step  19900 | Loss: 4.6142 | LR: 3.13e-04 | Speed: 5.6 steps/s\n",
      "Step  20000 | Loss: 3.9430 | LR: 3.12e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.7152\n",
      "  >> New best model saved!\n",
      "  >> Checkpoint saved: checkpoint_step_20000.pt\n",
      "Step  20100 | Loss: 4.5271 | LR: 3.12e-04 | Speed: 3.5 steps/s\n",
      "Step  20200 | Loss: 4.3987 | LR: 3.11e-04 | Speed: 5.6 steps/s\n",
      "Step  20300 | Loss: 4.1029 | LR: 3.10e-04 | Speed: 5.7 steps/s\n",
      "Step  20400 | Loss: 4.4755 | LR: 3.09e-04 | Speed: 5.6 steps/s\n",
      "Step  20500 | Loss: 4.6641 | LR: 3.09e-04 | Speed: 5.6 steps/s\n",
      "Step  20600 | Loss: 4.2082 | LR: 3.08e-04 | Speed: 5.6 steps/s\n",
      "Step  20700 | Loss: 4.1179 | LR: 3.07e-04 | Speed: 5.6 steps/s\n",
      "Step  20800 | Loss: 4.7261 | LR: 3.06e-04 | Speed: 5.6 steps/s\n",
      "Step  20900 | Loss: 4.0137 | LR: 3.06e-04 | Speed: 4.6 steps/s\n",
      "Step  21000 | Loss: 4.4991 | LR: 3.05e-04 | Speed: 5.7 steps/s\n",
      "Step  21100 | Loss: 4.4664 | LR: 3.04e-04 | Speed: 5.6 steps/s\n",
      "Step  21200 | Loss: 4.4286 | LR: 3.04e-04 | Speed: 5.6 steps/s\n",
      "Step  21300 | Loss: 4.5531 | LR: 3.03e-04 | Speed: 5.6 steps/s\n",
      "Step  21400 | Loss: 4.5549 | LR: 3.02e-04 | Speed: 5.6 steps/s\n",
      "Step  21500 | Loss: 4.3781 | LR: 3.01e-04 | Speed: 5.6 steps/s\n",
      "Step  21600 | Loss: 4.0113 | LR: 3.01e-04 | Speed: 5.6 steps/s\n",
      "Step  21700 | Loss: 4.0885 | LR: 3.00e-04 | Speed: 5.7 steps/s\n",
      "Step  21800 | Loss: 3.7828 | LR: 2.99e-04 | Speed: 5.7 steps/s\n",
      "Step  21900 | Loss: 4.0965 | LR: 2.99e-04 | Speed: 5.6 steps/s\n",
      "Step  22000 | Loss: 4.4265 | LR: 2.98e-04 | Speed: 5.5 steps/s\n",
      "  >> Validation loss: 4.7012\n",
      "  >> New best model saved!\n",
      "Step  22100 | Loss: 4.1338 | LR: 2.97e-04 | Speed: 4.5 steps/s\n",
      "Step  22200 | Loss: 4.4943 | LR: 2.97e-04 | Speed: 5.6 steps/s\n",
      "Step  22300 | Loss: 3.9553 | LR: 2.96e-04 | Speed: 5.5 steps/s\n",
      "Step  22400 | Loss: 4.0425 | LR: 2.95e-04 | Speed: 5.6 steps/s\n",
      "Step  22500 | Loss: 4.0464 | LR: 2.95e-04 | Speed: 5.6 steps/s\n",
      "Step  22600 | Loss: 4.2929 | LR: 2.94e-04 | Speed: 5.6 steps/s\n",
      "Step  22700 | Loss: 4.3866 | LR: 2.93e-04 | Speed: 5.5 steps/s\n",
      "Step  22800 | Loss: 4.0452 | LR: 2.93e-04 | Speed: 5.6 steps/s\n",
      "\n",
      "--- Epoch 2 completed ---\n",
      "\n",
      "Step  22900 | Loss: 4.6188 | LR: 2.92e-04 | Speed: 5.3 steps/s\n",
      "Step  23000 | Loss: 4.0951 | LR: 2.91e-04 | Speed: 5.6 steps/s\n",
      "Step  23100 | Loss: 4.5321 | LR: 2.91e-04 | Speed: 5.6 steps/s\n",
      "Step  23200 | Loss: 4.4410 | LR: 2.90e-04 | Speed: 5.6 steps/s\n",
      "Step  23300 | Loss: 4.1967 | LR: 2.90e-04 | Speed: 5.6 steps/s\n",
      "Step  23400 | Loss: 4.5840 | LR: 2.89e-04 | Speed: 5.6 steps/s\n",
      "Step  23500 | Loss: 4.1963 | LR: 2.88e-04 | Speed: 5.7 steps/s\n",
      "Step  23600 | Loss: 4.2823 | LR: 2.88e-04 | Speed: 5.6 steps/s\n",
      "Step  23700 | Loss: 4.5001 | LR: 2.87e-04 | Speed: 5.6 steps/s\n",
      "Step  23800 | Loss: 4.0826 | LR: 2.86e-04 | Speed: 5.5 steps/s\n",
      "Step  23900 | Loss: 4.0428 | LR: 2.86e-04 | Speed: 5.6 steps/s\n",
      "Step  24000 | Loss: 4.1499 | LR: 2.85e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.6769\n",
      "  >> New best model saved!\n",
      "Step  24100 | Loss: 3.0535 | LR: 2.85e-04 | Speed: 4.5 steps/s\n",
      "Step  24200 | Loss: 4.0789 | LR: 2.84e-04 | Speed: 5.5 steps/s\n",
      "Step  24300 | Loss: 3.9178 | LR: 2.83e-04 | Speed: 5.6 steps/s\n",
      "Step  24400 | Loss: 4.2166 | LR: 2.83e-04 | Speed: 5.6 steps/s\n",
      "Step  24500 | Loss: 3.9086 | LR: 2.82e-04 | Speed: 5.6 steps/s\n",
      "Step  24600 | Loss: 4.1682 | LR: 2.82e-04 | Speed: 5.6 steps/s\n",
      "Step  24700 | Loss: 4.5375 | LR: 2.81e-04 | Speed: 5.5 steps/s\n",
      "Step  24800 | Loss: 4.1155 | LR: 2.81e-04 | Speed: 5.7 steps/s\n",
      "Step  24900 | Loss: 4.5295 | LR: 2.80e-04 | Speed: 5.6 steps/s\n",
      "Step  25000 | Loss: 3.8579 | LR: 2.80e-04 | Speed: 5.6 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_25000.pt\n",
      "Step  25100 | Loss: 4.5078 | LR: 2.79e-04 | Speed: 4.2 steps/s\n",
      "Step  25200 | Loss: 4.0648 | LR: 2.78e-04 | Speed: 5.5 steps/s\n",
      "Step  25300 | Loss: 3.6845 | LR: 2.78e-04 | Speed: 5.6 steps/s\n",
      "Step  25400 | Loss: 4.1628 | LR: 2.77e-04 | Speed: 5.6 steps/s\n",
      "Step  25500 | Loss: 4.0863 | LR: 2.77e-04 | Speed: 5.6 steps/s\n",
      "Step  25600 | Loss: 4.0844 | LR: 2.76e-04 | Speed: 5.6 steps/s\n",
      "Step  25700 | Loss: 3.8992 | LR: 2.76e-04 | Speed: 5.6 steps/s\n",
      "Step  25800 | Loss: 4.4645 | LR: 2.75e-04 | Speed: 5.5 steps/s\n",
      "Step  25900 | Loss: 3.9116 | LR: 2.75e-04 | Speed: 5.6 steps/s\n",
      "Step  26000 | Loss: 4.2384 | LR: 2.74e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.6768\n",
      "  >> New best model saved!\n",
      "Step  26100 | Loss: 4.1358 | LR: 2.74e-04 | Speed: 4.5 steps/s\n",
      "Step  26200 | Loss: 4.0786 | LR: 2.73e-04 | Speed: 5.5 steps/s\n",
      "Step  26300 | Loss: 4.3113 | LR: 2.73e-04 | Speed: 5.6 steps/s\n",
      "Step  26400 | Loss: 4.1445 | LR: 2.72e-04 | Speed: 5.5 steps/s\n",
      "Step  26500 | Loss: 4.5791 | LR: 2.71e-04 | Speed: 5.6 steps/s\n",
      "Step  26600 | Loss: 4.1357 | LR: 2.71e-04 | Speed: 5.5 steps/s\n",
      "Step  26700 | Loss: 4.3266 | LR: 2.70e-04 | Speed: 5.6 steps/s\n",
      "Step  26800 | Loss: 3.5655 | LR: 2.70e-04 | Speed: 5.6 steps/s\n",
      "Step  26900 | Loss: 4.5687 | LR: 2.69e-04 | Speed: 5.6 steps/s\n",
      "Step  27000 | Loss: 4.4383 | LR: 2.69e-04 | Speed: 5.6 steps/s\n",
      "Step  27100 | Loss: 4.1690 | LR: 2.68e-04 | Speed: 5.5 steps/s\n",
      "Step  27200 | Loss: 4.2947 | LR: 2.68e-04 | Speed: 5.6 steps/s\n",
      "Step  27300 | Loss: 4.0326 | LR: 2.67e-04 | Speed: 5.6 steps/s\n",
      "Step  27400 | Loss: 4.1676 | LR: 2.67e-04 | Speed: 5.6 steps/s\n",
      "Step  27500 | Loss: 4.4857 | LR: 2.66e-04 | Speed: 5.6 steps/s\n",
      "Step  27600 | Loss: 4.0360 | LR: 2.66e-04 | Speed: 5.6 steps/s\n",
      "Step  27700 | Loss: 4.5769 | LR: 2.66e-04 | Speed: 5.7 steps/s\n",
      "Step  27800 | Loss: 4.1916 | LR: 2.65e-04 | Speed: 5.6 steps/s\n",
      "Step  27900 | Loss: 4.4543 | LR: 2.65e-04 | Speed: 5.6 steps/s\n",
      "Step  28000 | Loss: 4.2012 | LR: 2.64e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.6567\n",
      "  >> New best model saved!\n",
      "Step  28100 | Loss: 4.4704 | LR: 2.64e-04 | Speed: 4.5 steps/s\n",
      "Step  28200 | Loss: 4.0570 | LR: 2.63e-04 | Speed: 5.6 steps/s\n",
      "Step  28300 | Loss: 4.1223 | LR: 2.63e-04 | Speed: 5.6 steps/s\n",
      "Step  28400 | Loss: 3.8919 | LR: 2.62e-04 | Speed: 5.6 steps/s\n",
      "Step  28500 | Loss: 4.6773 | LR: 2.62e-04 | Speed: 5.6 steps/s\n",
      "Step  28600 | Loss: 4.0598 | LR: 2.61e-04 | Speed: 5.7 steps/s\n",
      "Step  28700 | Loss: 4.0290 | LR: 2.61e-04 | Speed: 5.2 steps/s\n",
      "Step  28800 | Loss: 4.2058 | LR: 2.60e-04 | Speed: 5.7 steps/s\n",
      "Step  28900 | Loss: 3.9109 | LR: 2.60e-04 | Speed: 5.6 steps/s\n",
      "Step  29000 | Loss: 4.2233 | LR: 2.60e-04 | Speed: 5.7 steps/s\n",
      "Step  29100 | Loss: 4.2720 | LR: 2.59e-04 | Speed: 5.7 steps/s\n",
      "Step  29200 | Loss: 3.9341 | LR: 2.59e-04 | Speed: 5.7 steps/s\n",
      "Step  29300 | Loss: 4.2836 | LR: 2.58e-04 | Speed: 5.7 steps/s\n",
      "Step  29400 | Loss: 4.1491 | LR: 2.58e-04 | Speed: 5.7 steps/s\n",
      "Step  29500 | Loss: 4.1177 | LR: 2.57e-04 | Speed: 5.7 steps/s\n",
      "Step  29600 | Loss: 3.8607 | LR: 2.57e-04 | Speed: 5.7 steps/s\n",
      "Step  29700 | Loss: 3.0488 | LR: 2.56e-04 | Speed: 5.7 steps/s\n",
      "Step  29800 | Loss: 3.7919 | LR: 2.56e-04 | Speed: 5.6 steps/s\n",
      "Step  29900 | Loss: 4.1355 | LR: 2.56e-04 | Speed: 5.6 steps/s\n",
      "Step  30000 | Loss: 4.0813 | LR: 2.55e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.6201\n",
      "  >> New best model saved!\n",
      "  >> Checkpoint saved: checkpoint_step_30000.pt\n",
      "Step  30100 | Loss: 3.7335 | LR: 2.55e-04 | Speed: 3.5 steps/s\n",
      "Step  30200 | Loss: 4.1907 | LR: 2.54e-04 | Speed: 5.7 steps/s\n",
      "Step  30300 | Loss: 3.7795 | LR: 2.54e-04 | Speed: 5.6 steps/s\n",
      "Step  30400 | Loss: 3.6777 | LR: 2.53e-04 | Speed: 5.7 steps/s\n",
      "Step  30500 | Loss: 4.1735 | LR: 2.53e-04 | Speed: 5.6 steps/s\n",
      "Step  30600 | Loss: 4.1861 | LR: 2.53e-04 | Speed: 5.6 steps/s\n",
      "Step  30700 | Loss: 4.0436 | LR: 2.52e-04 | Speed: 5.5 steps/s\n",
      "Step  30800 | Loss: 4.2408 | LR: 2.52e-04 | Speed: 5.6 steps/s\n",
      "Step  30900 | Loss: 4.1487 | LR: 2.51e-04 | Speed: 5.1 steps/s\n",
      "Step  31000 | Loss: 3.8099 | LR: 2.51e-04 | Speed: 5.6 steps/s\n",
      "Step  31100 | Loss: 4.5670 | LR: 2.51e-04 | Speed: 5.6 steps/s\n",
      "Step  31200 | Loss: 4.4756 | LR: 2.50e-04 | Speed: 5.6 steps/s\n",
      "Step  31300 | Loss: 4.4417 | LR: 2.50e-04 | Speed: 5.2 steps/s\n",
      "Step  31400 | Loss: 3.2582 | LR: 2.49e-04 | Speed: 5.7 steps/s\n",
      "Step  31500 | Loss: 4.1387 | LR: 2.49e-04 | Speed: 5.7 steps/s\n",
      "Step  31600 | Loss: 4.1771 | LR: 2.49e-04 | Speed: 5.6 steps/s\n",
      "Step  31700 | Loss: 3.8727 | LR: 2.48e-04 | Speed: 5.5 steps/s\n",
      "Step  31800 | Loss: 4.1977 | LR: 2.48e-04 | Speed: 5.6 steps/s\n",
      "Step  31900 | Loss: 4.0283 | LR: 2.47e-04 | Speed: 5.5 steps/s\n",
      "Step  32000 | Loss: 4.3876 | LR: 2.47e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.6215\n",
      "Step  32100 | Loss: 4.2461 | LR: 2.47e-04 | Speed: 5.2 steps/s\n",
      "Step  32200 | Loss: 3.9862 | LR: 2.46e-04 | Speed: 5.7 steps/s\n",
      "Step  32300 | Loss: 4.0759 | LR: 2.46e-04 | Speed: 5.7 steps/s\n",
      "Step  32400 | Loss: 3.6120 | LR: 2.46e-04 | Speed: 5.6 steps/s\n",
      "Step  32500 | Loss: 4.0443 | LR: 2.45e-04 | Speed: 5.6 steps/s\n",
      "Step  32600 | Loss: 4.3780 | LR: 2.45e-04 | Speed: 5.7 steps/s\n",
      "Step  32700 | Loss: 4.2524 | LR: 2.44e-04 | Speed: 5.6 steps/s\n",
      "Step  32800 | Loss: 3.7629 | LR: 2.44e-04 | Speed: 5.6 steps/s\n",
      "Step  32900 | Loss: 3.8781 | LR: 2.44e-04 | Speed: 5.6 steps/s\n",
      "Step  33000 | Loss: 4.0901 | LR: 2.43e-04 | Speed: 5.7 steps/s\n",
      "Step  33100 | Loss: 4.0555 | LR: 2.43e-04 | Speed: 5.6 steps/s\n",
      "Step  33200 | Loss: 4.0632 | LR: 2.43e-04 | Speed: 5.6 steps/s\n",
      "Step  33300 | Loss: 4.3358 | LR: 2.42e-04 | Speed: 5.6 steps/s\n",
      "Step  33400 | Loss: 4.2644 | LR: 2.42e-04 | Speed: 5.6 steps/s\n",
      "Step  33500 | Loss: 4.3817 | LR: 2.41e-04 | Speed: 5.6 steps/s\n",
      "Step  33600 | Loss: 3.8322 | LR: 2.41e-04 | Speed: 5.6 steps/s\n",
      "Step  33700 | Loss: 4.2313 | LR: 2.41e-04 | Speed: 5.6 steps/s\n",
      "Step  33800 | Loss: 4.5258 | LR: 2.40e-04 | Speed: 5.5 steps/s\n",
      "Step  33900 | Loss: 4.3679 | LR: 2.40e-04 | Speed: 5.7 steps/s\n",
      "Step  34000 | Loss: 3.6499 | LR: 2.40e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.6030\n",
      "  >> New best model saved!\n",
      "Step  34100 | Loss: 4.2841 | LR: 2.39e-04 | Speed: 4.5 steps/s\n",
      "Step  34200 | Loss: 4.4457 | LR: 2.39e-04 | Speed: 5.6 steps/s\n",
      "\n",
      "--- Epoch 3 completed ---\n",
      "\n",
      "Step  34300 | Loss: 3.6243 | LR: 2.39e-04 | Speed: 5.3 steps/s\n",
      "Step  34400 | Loss: 4.2148 | LR: 2.38e-04 | Speed: 5.6 steps/s\n",
      "Step  34500 | Loss: 3.8215 | LR: 2.38e-04 | Speed: 5.6 steps/s\n",
      "Step  34600 | Loss: 4.4673 | LR: 2.38e-04 | Speed: 5.6 steps/s\n",
      "Step  34700 | Loss: 4.4239 | LR: 2.37e-04 | Speed: 5.6 steps/s\n",
      "Step  34800 | Loss: 3.9535 | LR: 2.37e-04 | Speed: 5.6 steps/s\n",
      "Step  34900 | Loss: 3.9276 | LR: 2.37e-04 | Speed: 5.7 steps/s\n",
      "Step  35000 | Loss: 4.0212 | LR: 2.36e-04 | Speed: 5.6 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_35000.pt\n",
      "Step  35100 | Loss: 4.5115 | LR: 2.36e-04 | Speed: 4.1 steps/s\n",
      "Step  35200 | Loss: 4.6109 | LR: 2.36e-04 | Speed: 5.5 steps/s\n",
      "Step  35300 | Loss: 3.5359 | LR: 2.35e-04 | Speed: 5.6 steps/s\n",
      "Step  35400 | Loss: 4.3988 | LR: 2.35e-04 | Speed: 5.6 steps/s\n",
      "Step  35500 | Loss: 4.3326 | LR: 2.35e-04 | Speed: 5.6 steps/s\n",
      "Step  35600 | Loss: 4.2133 | LR: 2.34e-04 | Speed: 5.5 steps/s\n",
      "Step  35700 | Loss: 4.4309 | LR: 2.34e-04 | Speed: 5.5 steps/s\n",
      "Step  35800 | Loss: 4.3653 | LR: 2.34e-04 | Speed: 5.6 steps/s\n",
      "Step  35900 | Loss: 3.9993 | LR: 2.33e-04 | Speed: 5.6 steps/s\n",
      "Step  36000 | Loss: 4.4915 | LR: 2.33e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.5800\n",
      "  >> New best model saved!\n",
      "Step  36100 | Loss: 3.2255 | LR: 2.33e-04 | Speed: 4.5 steps/s\n",
      "Step  36200 | Loss: 4.3331 | LR: 2.32e-04 | Speed: 5.6 steps/s\n",
      "Step  36300 | Loss: 4.1835 | LR: 2.32e-04 | Speed: 5.6 steps/s\n",
      "Step  36400 | Loss: 4.2079 | LR: 2.32e-04 | Speed: 5.6 steps/s\n",
      "Step  36500 | Loss: 4.0267 | LR: 2.31e-04 | Speed: 5.6 steps/s\n",
      "Step  36600 | Loss: 4.1087 | LR: 2.31e-04 | Speed: 5.7 steps/s\n",
      "Step  36700 | Loss: 3.8304 | LR: 2.31e-04 | Speed: 5.6 steps/s\n",
      "Step  36800 | Loss: 3.6740 | LR: 2.30e-04 | Speed: 5.6 steps/s\n",
      "Step  36900 | Loss: 4.2660 | LR: 2.30e-04 | Speed: 5.5 steps/s\n",
      "Step  37000 | Loss: 4.3434 | LR: 2.30e-04 | Speed: 5.5 steps/s\n",
      "Step  37100 | Loss: 4.0971 | LR: 2.29e-04 | Speed: 5.7 steps/s\n",
      "Step  37200 | Loss: 3.8775 | LR: 2.29e-04 | Speed: 5.6 steps/s\n",
      "Step  37300 | Loss: 3.9604 | LR: 2.29e-04 | Speed: 5.5 steps/s\n",
      "Step  37400 | Loss: 4.1437 | LR: 2.29e-04 | Speed: 5.7 steps/s\n",
      "Step  37500 | Loss: 4.1511 | LR: 2.28e-04 | Speed: 5.6 steps/s\n",
      "Step  37600 | Loss: 4.7781 | LR: 2.28e-04 | Speed: 5.6 steps/s\n",
      "Step  37700 | Loss: 4.2585 | LR: 2.28e-04 | Speed: 5.6 steps/s\n",
      "Step  37800 | Loss: 3.4910 | LR: 2.27e-04 | Speed: 5.6 steps/s\n",
      "Step  37900 | Loss: 4.2902 | LR: 2.27e-04 | Speed: 5.6 steps/s\n",
      "Step  38000 | Loss: 3.7730 | LR: 2.27e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.5808\n",
      "Step  38100 | Loss: 3.6764 | LR: 2.26e-04 | Speed: 5.1 steps/s\n",
      "Step  38200 | Loss: 3.9940 | LR: 2.26e-04 | Speed: 5.5 steps/s\n",
      "Step  38300 | Loss: 4.1742 | LR: 2.26e-04 | Speed: 5.6 steps/s\n",
      "Step  38400 | Loss: 4.3206 | LR: 2.26e-04 | Speed: 5.7 steps/s\n",
      "Step  38500 | Loss: 3.8086 | LR: 2.25e-04 | Speed: 5.6 steps/s\n",
      "Step  38600 | Loss: 4.6585 | LR: 2.25e-04 | Speed: 5.6 steps/s\n",
      "Step  38700 | Loss: 4.1365 | LR: 2.25e-04 | Speed: 5.6 steps/s\n",
      "Step  38800 | Loss: 3.6538 | LR: 2.24e-04 | Speed: 5.7 steps/s\n",
      "Step  38900 | Loss: 4.1406 | LR: 2.24e-04 | Speed: 5.5 steps/s\n",
      "Step  39000 | Loss: 3.8359 | LR: 2.24e-04 | Speed: 5.6 steps/s\n",
      "Step  39100 | Loss: 4.1860 | LR: 2.23e-04 | Speed: 5.7 steps/s\n",
      "Step  39200 | Loss: 4.1476 | LR: 2.23e-04 | Speed: 5.8 steps/s\n",
      "Step  39300 | Loss: 3.9760 | LR: 2.23e-04 | Speed: 5.6 steps/s\n",
      "Step  39400 | Loss: 4.1366 | LR: 2.23e-04 | Speed: 5.7 steps/s\n",
      "Step  39500 | Loss: 3.9390 | LR: 2.22e-04 | Speed: 5.6 steps/s\n",
      "Step  39600 | Loss: 4.0257 | LR: 2.22e-04 | Speed: 5.6 steps/s\n",
      "Step  39700 | Loss: 3.6608 | LR: 2.22e-04 | Speed: 5.6 steps/s\n",
      "Step  39800 | Loss: 4.3139 | LR: 2.22e-04 | Speed: 5.6 steps/s\n",
      "Step  39900 | Loss: 4.0094 | LR: 2.21e-04 | Speed: 5.6 steps/s\n",
      "Step  40000 | Loss: 4.2234 | LR: 2.21e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.5722\n",
      "  >> New best model saved!\n",
      "  >> Checkpoint saved: checkpoint_step_40000.pt\n",
      "Step  40100 | Loss: 4.6572 | LR: 2.21e-04 | Speed: 3.6 steps/s\n",
      "Step  40200 | Loss: 4.4805 | LR: 2.20e-04 | Speed: 5.6 steps/s\n",
      "Step  40300 | Loss: 3.5110 | LR: 2.20e-04 | Speed: 5.7 steps/s\n",
      "Step  40400 | Loss: 4.1305 | LR: 2.20e-04 | Speed: 5.6 steps/s\n",
      "Step  40500 | Loss: 4.0259 | LR: 2.20e-04 | Speed: 5.7 steps/s\n",
      "Step  40600 | Loss: 3.9599 | LR: 2.19e-04 | Speed: 5.6 steps/s\n",
      "Step  40700 | Loss: 4.0209 | LR: 2.19e-04 | Speed: 5.6 steps/s\n",
      "Step  40800 | Loss: 4.1097 | LR: 2.19e-04 | Speed: 5.6 steps/s\n",
      "Step  40900 | Loss: 3.9488 | LR: 2.19e-04 | Speed: 5.6 steps/s\n",
      "Step  41000 | Loss: 4.0682 | LR: 2.18e-04 | Speed: 5.6 steps/s\n",
      "Step  41100 | Loss: 4.0177 | LR: 2.18e-04 | Speed: 5.7 steps/s\n",
      "Step  41200 | Loss: 3.8530 | LR: 2.18e-04 | Speed: 5.3 steps/s\n",
      "Step  41300 | Loss: 4.1085 | LR: 2.17e-04 | Speed: 5.3 steps/s\n",
      "Step  41400 | Loss: 4.2381 | LR: 2.17e-04 | Speed: 5.7 steps/s\n",
      "Step  41500 | Loss: 4.3540 | LR: 2.17e-04 | Speed: 5.7 steps/s\n",
      "Step  41600 | Loss: 3.8653 | LR: 2.17e-04 | Speed: 5.2 steps/s\n",
      "Step  41700 | Loss: 3.9567 | LR: 2.16e-04 | Speed: 5.7 steps/s\n",
      "Step  41800 | Loss: 4.2591 | LR: 2.16e-04 | Speed: 5.6 steps/s\n",
      "Step  41900 | Loss: 3.7381 | LR: 2.16e-04 | Speed: 5.6 steps/s\n",
      "Step  42000 | Loss: 3.7118 | LR: 2.16e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.5692\n",
      "  >> New best model saved!\n",
      "Step  42100 | Loss: 4.0898 | LR: 2.15e-04 | Speed: 4.5 steps/s\n",
      "Step  42200 | Loss: 4.2799 | LR: 2.15e-04 | Speed: 5.7 steps/s\n",
      "Step  42300 | Loss: 4.4907 | LR: 2.15e-04 | Speed: 5.6 steps/s\n",
      "Step  42400 | Loss: 3.7262 | LR: 2.15e-04 | Speed: 5.7 steps/s\n",
      "Step  42500 | Loss: 4.2532 | LR: 2.14e-04 | Speed: 5.5 steps/s\n",
      "Step  42600 | Loss: 4.3798 | LR: 2.14e-04 | Speed: 5.7 steps/s\n",
      "Step  42700 | Loss: 3.9977 | LR: 2.14e-04 | Speed: 5.6 steps/s\n",
      "Step  42800 | Loss: 3.8597 | LR: 2.14e-04 | Speed: 5.7 steps/s\n",
      "Step  42900 | Loss: 3.4474 | LR: 2.13e-04 | Speed: 5.6 steps/s\n",
      "Step  43000 | Loss: 4.2339 | LR: 2.13e-04 | Speed: 5.5 steps/s\n",
      "Step  43100 | Loss: 4.1979 | LR: 2.13e-04 | Speed: 5.6 steps/s\n",
      "Step  43200 | Loss: 4.0278 | LR: 2.13e-04 | Speed: 5.5 steps/s\n",
      "Step  43300 | Loss: 3.5072 | LR: 2.12e-04 | Speed: 5.5 steps/s\n",
      "Step  43400 | Loss: 3.9978 | LR: 2.12e-04 | Speed: 5.6 steps/s\n",
      "Step  43500 | Loss: 4.0105 | LR: 2.12e-04 | Speed: 5.6 steps/s\n",
      "Step  43600 | Loss: 4.5960 | LR: 2.12e-04 | Speed: 5.7 steps/s\n",
      "Step  43700 | Loss: 3.9357 | LR: 2.11e-04 | Speed: 5.6 steps/s\n",
      "Step  43800 | Loss: 3.9090 | LR: 2.11e-04 | Speed: 5.7 steps/s\n",
      "Step  43900 | Loss: 3.7381 | LR: 2.11e-04 | Speed: 5.7 steps/s\n",
      "Step  44000 | Loss: 4.0721 | LR: 2.11e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.5696\n",
      "Step  44100 | Loss: 4.3489 | LR: 2.10e-04 | Speed: 5.2 steps/s\n",
      "Step  44200 | Loss: 3.6787 | LR: 2.10e-04 | Speed: 5.6 steps/s\n",
      "Step  44300 | Loss: 3.8661 | LR: 2.10e-04 | Speed: 5.6 steps/s\n",
      "Step  44400 | Loss: 4.0723 | LR: 2.10e-04 | Speed: 5.7 steps/s\n",
      "Step  44500 | Loss: 3.5543 | LR: 2.09e-04 | Speed: 5.6 steps/s\n",
      "Step  44600 | Loss: 3.7227 | LR: 2.09e-04 | Speed: 5.6 steps/s\n",
      "Step  44700 | Loss: 3.9336 | LR: 2.09e-04 | Speed: 5.7 steps/s\n",
      "Step  44800 | Loss: 3.7558 | LR: 2.09e-04 | Speed: 5.6 steps/s\n",
      "Step  44900 | Loss: 3.7413 | LR: 2.09e-04 | Speed: 5.7 steps/s\n",
      "Step  45000 | Loss: 3.9754 | LR: 2.08e-04 | Speed: 5.7 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_45000.pt\n",
      "Step  45100 | Loss: 4.2267 | LR: 2.08e-04 | Speed: 4.2 steps/s\n",
      "Step  45200 | Loss: 4.0713 | LR: 2.08e-04 | Speed: 5.6 steps/s\n",
      "Step  45300 | Loss: 4.3024 | LR: 2.08e-04 | Speed: 5.7 steps/s\n",
      "Step  45400 | Loss: 4.8241 | LR: 2.07e-04 | Speed: 5.7 steps/s\n",
      "Step  45500 | Loss: 2.9179 | LR: 2.07e-04 | Speed: 5.8 steps/s\n",
      "Step  45600 | Loss: 3.8270 | LR: 2.07e-04 | Speed: 5.6 steps/s\n",
      "Step  45700 | Loss: 4.2138 | LR: 2.07e-04 | Speed: 5.6 steps/s\n",
      "\n",
      "--- Epoch 4 completed ---\n",
      "\n",
      "Step  45800 | Loss: 4.1600 | LR: 2.07e-04 | Speed: 5.3 steps/s\n",
      "Step  45900 | Loss: 3.8023 | LR: 2.06e-04 | Speed: 5.6 steps/s\n",
      "Step  46000 | Loss: 4.3680 | LR: 2.06e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.5524\n",
      "  >> New best model saved!\n",
      "Step  46100 | Loss: 3.6820 | LR: 2.06e-04 | Speed: 4.5 steps/s\n",
      "Step  46200 | Loss: 4.1441 | LR: 2.06e-04 | Speed: 5.5 steps/s\n",
      "Step  46300 | Loss: 4.0255 | LR: 2.05e-04 | Speed: 5.6 steps/s\n",
      "Step  46400 | Loss: 3.8433 | LR: 2.05e-04 | Speed: 5.5 steps/s\n",
      "Step  46500 | Loss: 3.8434 | LR: 2.05e-04 | Speed: 5.6 steps/s\n",
      "Step  46600 | Loss: 4.1448 | LR: 2.05e-04 | Speed: 5.6 steps/s\n",
      "Step  46700 | Loss: 4.1462 | LR: 2.05e-04 | Speed: 5.6 steps/s\n",
      "Step  46800 | Loss: 4.1516 | LR: 2.04e-04 | Speed: 5.6 steps/s\n",
      "Step  46900 | Loss: 4.3982 | LR: 2.04e-04 | Speed: 5.6 steps/s\n",
      "Step  47000 | Loss: 3.8784 | LR: 2.04e-04 | Speed: 5.6 steps/s\n",
      "Step  47100 | Loss: 3.4663 | LR: 2.04e-04 | Speed: 5.6 steps/s\n",
      "Step  47200 | Loss: 3.7357 | LR: 2.03e-04 | Speed: 5.6 steps/s\n",
      "Step  47300 | Loss: 3.8809 | LR: 2.03e-04 | Speed: 5.6 steps/s\n",
      "Step  47400 | Loss: 3.3205 | LR: 2.03e-04 | Speed: 5.6 steps/s\n",
      "Step  47500 | Loss: 4.1117 | LR: 2.03e-04 | Speed: 5.5 steps/s\n",
      "Step  47600 | Loss: 3.6555 | LR: 2.03e-04 | Speed: 5.6 steps/s\n",
      "Step  47700 | Loss: 3.8266 | LR: 2.02e-04 | Speed: 5.5 steps/s\n",
      "Step  47800 | Loss: 4.4349 | LR: 2.02e-04 | Speed: 5.5 steps/s\n",
      "Step  47900 | Loss: 3.6261 | LR: 2.02e-04 | Speed: 5.6 steps/s\n",
      "Step  48000 | Loss: 4.1734 | LR: 2.02e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.5304\n",
      "  >> New best model saved!\n",
      "Step  48100 | Loss: 3.5892 | LR: 2.02e-04 | Speed: 4.5 steps/s\n",
      "Step  48200 | Loss: 4.5891 | LR: 2.01e-04 | Speed: 5.6 steps/s\n",
      "Step  48300 | Loss: 3.5261 | LR: 2.01e-04 | Speed: 5.6 steps/s\n",
      "Step  48400 | Loss: 3.8728 | LR: 2.01e-04 | Speed: 5.6 steps/s\n",
      "Step  48500 | Loss: 4.0069 | LR: 2.01e-04 | Speed: 5.5 steps/s\n",
      "Step  48600 | Loss: 4.2713 | LR: 2.00e-04 | Speed: 5.6 steps/s\n",
      "Step  48700 | Loss: 4.0145 | LR: 2.00e-04 | Speed: 5.6 steps/s\n",
      "Step  48800 | Loss: 3.7073 | LR: 2.00e-04 | Speed: 5.5 steps/s\n",
      "Step  48900 | Loss: 4.3054 | LR: 2.00e-04 | Speed: 5.5 steps/s\n",
      "Step  49000 | Loss: 3.9296 | LR: 2.00e-04 | Speed: 5.6 steps/s\n",
      "Step  49100 | Loss: 4.1338 | LR: 1.99e-04 | Speed: 5.6 steps/s\n",
      "Step  49200 | Loss: 3.9594 | LR: 1.99e-04 | Speed: 5.5 steps/s\n",
      "Step  49300 | Loss: 3.9727 | LR: 1.99e-04 | Speed: 5.6 steps/s\n",
      "Step  49400 | Loss: 3.8072 | LR: 1.99e-04 | Speed: 5.6 steps/s\n",
      "Step  49500 | Loss: 3.4950 | LR: 1.99e-04 | Speed: 5.6 steps/s\n",
      "Step  49600 | Loss: 4.1910 | LR: 1.98e-04 | Speed: 5.5 steps/s\n",
      "Step  49700 | Loss: 3.4912 | LR: 1.98e-04 | Speed: 5.6 steps/s\n",
      "Step  49800 | Loss: 3.7786 | LR: 1.98e-04 | Speed: 5.6 steps/s\n",
      "Step  49900 | Loss: 4.1228 | LR: 1.98e-04 | Speed: 5.6 steps/s\n",
      "Step  50000 | Loss: 3.9530 | LR: 1.98e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.5494\n",
      "  >> Checkpoint saved: checkpoint_step_50000.pt\n",
      "Step  50100 | Loss: 3.9495 | LR: 1.97e-04 | Speed: 3.9 steps/s\n",
      "Step  50200 | Loss: 4.1038 | LR: 1.97e-04 | Speed: 5.5 steps/s\n",
      "Step  50300 | Loss: 3.7185 | LR: 1.97e-04 | Speed: 5.6 steps/s\n",
      "Step  50400 | Loss: 3.9411 | LR: 1.97e-04 | Speed: 5.6 steps/s\n",
      "Step  50500 | Loss: 4.0243 | LR: 1.97e-04 | Speed: 5.5 steps/s\n",
      "Step  50600 | Loss: 4.1286 | LR: 1.96e-04 | Speed: 5.5 steps/s\n",
      "Step  50700 | Loss: 4.2539 | LR: 1.96e-04 | Speed: 5.6 steps/s\n",
      "Step  50800 | Loss: 4.0867 | LR: 1.96e-04 | Speed: 5.7 steps/s\n",
      "Step  50900 | Loss: 4.0447 | LR: 1.96e-04 | Speed: 5.6 steps/s\n",
      "Step  51000 | Loss: 3.9978 | LR: 1.96e-04 | Speed: 5.7 steps/s\n",
      "Step  51100 | Loss: 4.6016 | LR: 1.96e-04 | Speed: 5.7 steps/s\n",
      "Step  51200 | Loss: 3.7817 | LR: 1.95e-04 | Speed: 5.6 steps/s\n",
      "Step  51300 | Loss: 3.7711 | LR: 1.95e-04 | Speed: 5.7 steps/s\n",
      "Step  51400 | Loss: 3.8039 | LR: 1.95e-04 | Speed: 5.7 steps/s\n",
      "Step  51500 | Loss: 3.9336 | LR: 1.95e-04 | Speed: 5.6 steps/s\n",
      "Step  51600 | Loss: 3.9219 | LR: 1.95e-04 | Speed: 5.0 steps/s\n",
      "Step  51700 | Loss: 4.2589 | LR: 1.94e-04 | Speed: 5.1 steps/s\n",
      "Step  51800 | Loss: 3.9032 | LR: 1.94e-04 | Speed: 5.7 steps/s\n",
      "Step  51900 | Loss: 3.9348 | LR: 1.94e-04 | Speed: 5.7 steps/s\n",
      "Step  52000 | Loss: 3.9992 | LR: 1.94e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.5337\n",
      "Step  52100 | Loss: 3.5161 | LR: 1.94e-04 | Speed: 5.1 steps/s\n",
      "Step  52200 | Loss: 3.6766 | LR: 1.93e-04 | Speed: 5.6 steps/s\n",
      "Step  52300 | Loss: 3.8174 | LR: 1.93e-04 | Speed: 5.6 steps/s\n",
      "Step  52400 | Loss: 3.8068 | LR: 1.93e-04 | Speed: 5.6 steps/s\n",
      "Step  52500 | Loss: 3.7446 | LR: 1.93e-04 | Speed: 5.6 steps/s\n",
      "Step  52600 | Loss: 3.8802 | LR: 1.93e-04 | Speed: 5.7 steps/s\n",
      "Step  52700 | Loss: 4.0270 | LR: 1.93e-04 | Speed: 5.6 steps/s\n",
      "Step  52800 | Loss: 3.6070 | LR: 1.92e-04 | Speed: 5.6 steps/s\n",
      "Step  52900 | Loss: 4.2605 | LR: 1.92e-04 | Speed: 5.6 steps/s\n",
      "Step  53000 | Loss: 3.7741 | LR: 1.92e-04 | Speed: 5.6 steps/s\n",
      "Step  53100 | Loss: 4.0915 | LR: 1.92e-04 | Speed: 5.6 steps/s\n",
      "Step  53200 | Loss: 3.5629 | LR: 1.92e-04 | Speed: 5.8 steps/s\n",
      "Step  53300 | Loss: 4.0352 | LR: 1.91e-04 | Speed: 5.4 steps/s\n",
      "Step  53400 | Loss: 3.7586 | LR: 1.91e-04 | Speed: 5.7 steps/s\n",
      "Step  53500 | Loss: 4.0886 | LR: 1.91e-04 | Speed: 5.6 steps/s\n",
      "Step  53600 | Loss: 3.8314 | LR: 1.91e-04 | Speed: 5.6 steps/s\n",
      "Step  53700 | Loss: 4.1139 | LR: 1.91e-04 | Speed: 5.6 steps/s\n",
      "Step  53800 | Loss: 4.0102 | LR: 1.91e-04 | Speed: 5.6 steps/s\n",
      "Step  53900 | Loss: 4.2288 | LR: 1.90e-04 | Speed: 5.6 steps/s\n",
      "Step  54000 | Loss: 3.7982 | LR: 1.90e-04 | Speed: 5.5 steps/s\n",
      "  >> Validation loss: 4.5221\n",
      "  >> New best model saved!\n",
      "Step  54100 | Loss: 3.8995 | LR: 1.90e-04 | Speed: 4.5 steps/s\n",
      "Step  54200 | Loss: 3.7048 | LR: 1.90e-04 | Speed: 5.7 steps/s\n",
      "Step  54300 | Loss: 4.3491 | LR: 1.90e-04 | Speed: 5.6 steps/s\n",
      "Step  54400 | Loss: 4.4093 | LR: 1.89e-04 | Speed: 5.6 steps/s\n",
      "Step  54500 | Loss: 4.2171 | LR: 1.89e-04 | Speed: 5.6 steps/s\n",
      "Step  54600 | Loss: 4.2409 | LR: 1.89e-04 | Speed: 5.7 steps/s\n",
      "Step  54700 | Loss: 4.2489 | LR: 1.89e-04 | Speed: 5.5 steps/s\n",
      "Step  54800 | Loss: 4.1027 | LR: 1.89e-04 | Speed: 5.6 steps/s\n",
      "Step  54900 | Loss: 4.2419 | LR: 1.89e-04 | Speed: 5.6 steps/s\n",
      "Step  55000 | Loss: 3.8013 | LR: 1.88e-04 | Speed: 5.6 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_55000.pt\n",
      "Step  55100 | Loss: 3.7280 | LR: 1.88e-04 | Speed: 4.2 steps/s\n",
      "Step  55200 | Loss: 4.1078 | LR: 1.88e-04 | Speed: 5.3 steps/s\n",
      "Step  55300 | Loss: 3.8990 | LR: 1.88e-04 | Speed: 5.6 steps/s\n",
      "Step  55400 | Loss: 3.8626 | LR: 1.88e-04 | Speed: 5.6 steps/s\n",
      "Step  55500 | Loss: 3.9356 | LR: 1.88e-04 | Speed: 5.7 steps/s\n",
      "Step  55600 | Loss: 4.0579 | LR: 1.87e-04 | Speed: 5.5 steps/s\n",
      "Step  55700 | Loss: 3.9760 | LR: 1.87e-04 | Speed: 5.7 steps/s\n",
      "Step  55800 | Loss: 3.3285 | LR: 1.87e-04 | Speed: 5.7 steps/s\n",
      "Step  55900 | Loss: 4.0458 | LR: 1.87e-04 | Speed: 5.7 steps/s\n",
      "Step  56000 | Loss: 3.4082 | LR: 1.87e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.4959\n",
      "  >> New best model saved!\n",
      "Step  56100 | Loss: 4.0174 | LR: 1.87e-04 | Speed: 4.5 steps/s\n",
      "Step  56200 | Loss: 3.6567 | LR: 1.86e-04 | Speed: 5.6 steps/s\n",
      "Step  56300 | Loss: 3.4628 | LR: 1.86e-04 | Speed: 5.6 steps/s\n",
      "Step  56400 | Loss: 3.9903 | LR: 1.86e-04 | Speed: 5.6 steps/s\n",
      "Step  56500 | Loss: 3.9961 | LR: 1.86e-04 | Speed: 5.6 steps/s\n",
      "Step  56600 | Loss: 4.4423 | LR: 1.86e-04 | Speed: 5.6 steps/s\n",
      "Step  56700 | Loss: 4.4620 | LR: 1.86e-04 | Speed: 5.7 steps/s\n",
      "Step  56800 | Loss: 3.9960 | LR: 1.85e-04 | Speed: 5.6 steps/s\n",
      "Step  56900 | Loss: 3.6547 | LR: 1.85e-04 | Speed: 5.6 steps/s\n",
      "Step  57000 | Loss: 3.5963 | LR: 1.85e-04 | Speed: 5.6 steps/s\n",
      "Step  57100 | Loss: 3.8609 | LR: 1.85e-04 | Speed: 5.6 steps/s\n",
      "\n",
      "--- Epoch 5 completed ---\n",
      "\n",
      "Step  57200 | Loss: 3.7523 | LR: 1.85e-04 | Speed: 5.3 steps/s\n",
      "Step  57300 | Loss: 3.8244 | LR: 1.85e-04 | Speed: 5.6 steps/s\n",
      "Step  57400 | Loss: 3.6145 | LR: 1.84e-04 | Speed: 5.5 steps/s\n",
      "Step  57500 | Loss: 4.4696 | LR: 1.84e-04 | Speed: 5.6 steps/s\n",
      "Step  57600 | Loss: 3.5699 | LR: 1.84e-04 | Speed: 5.7 steps/s\n",
      "Step  57700 | Loss: 3.6111 | LR: 1.84e-04 | Speed: 5.7 steps/s\n",
      "Step  57800 | Loss: 3.9763 | LR: 1.84e-04 | Speed: 5.7 steps/s\n",
      "Step  57900 | Loss: 3.4740 | LR: 1.84e-04 | Speed: 5.7 steps/s\n",
      "Step  58000 | Loss: 4.0705 | LR: 1.84e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.5085\n",
      "Step  58100 | Loss: 4.5166 | LR: 1.83e-04 | Speed: 5.2 steps/s\n",
      "Step  58200 | Loss: 4.0926 | LR: 1.83e-04 | Speed: 5.7 steps/s\n",
      "Step  58300 | Loss: 3.9404 | LR: 1.83e-04 | Speed: 5.6 steps/s\n",
      "Step  58400 | Loss: 3.9978 | LR: 1.83e-04 | Speed: 5.6 steps/s\n",
      "Step  58500 | Loss: 3.9097 | LR: 1.83e-04 | Speed: 5.7 steps/s\n",
      "Step  58600 | Loss: 3.9464 | LR: 1.83e-04 | Speed: 5.6 steps/s\n",
      "Step  58700 | Loss: 4.0969 | LR: 1.82e-04 | Speed: 5.6 steps/s\n",
      "Step  58800 | Loss: 4.3509 | LR: 1.82e-04 | Speed: 5.6 steps/s\n",
      "Step  58900 | Loss: 3.8540 | LR: 1.82e-04 | Speed: 5.6 steps/s\n",
      "Step  59000 | Loss: 4.0549 | LR: 1.82e-04 | Speed: 5.8 steps/s\n",
      "Step  59100 | Loss: 3.8414 | LR: 1.82e-04 | Speed: 5.7 steps/s\n",
      "Step  59200 | Loss: 4.1704 | LR: 1.82e-04 | Speed: 5.6 steps/s\n",
      "Step  59300 | Loss: 4.3340 | LR: 1.81e-04 | Speed: 5.6 steps/s\n",
      "Step  59400 | Loss: 4.2863 | LR: 1.81e-04 | Speed: 5.7 steps/s\n",
      "Step  59500 | Loss: 4.2441 | LR: 1.81e-04 | Speed: 5.7 steps/s\n",
      "Step  59600 | Loss: 4.0883 | LR: 1.81e-04 | Speed: 5.5 steps/s\n",
      "Step  59700 | Loss: 4.0942 | LR: 1.81e-04 | Speed: 5.7 steps/s\n",
      "Step  59800 | Loss: 4.0935 | LR: 1.81e-04 | Speed: 5.6 steps/s\n",
      "Step  59900 | Loss: 4.1407 | LR: 1.81e-04 | Speed: 5.1 steps/s\n",
      "Step  60000 | Loss: 4.1222 | LR: 1.80e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4885\n",
      "  >> New best model saved!\n",
      "  >> Checkpoint saved: checkpoint_step_60000.pt\n",
      "Step  60100 | Loss: 3.6657 | LR: 1.80e-04 | Speed: 3.5 steps/s\n",
      "Step  60200 | Loss: 4.0994 | LR: 1.80e-04 | Speed: 5.6 steps/s\n",
      "Step  60300 | Loss: 3.8477 | LR: 1.80e-04 | Speed: 5.6 steps/s\n",
      "Step  60400 | Loss: 4.2428 | LR: 1.80e-04 | Speed: 5.6 steps/s\n",
      "Step  60500 | Loss: 4.1084 | LR: 1.80e-04 | Speed: 5.6 steps/s\n",
      "Step  60600 | Loss: 3.9024 | LR: 1.80e-04 | Speed: 5.6 steps/s\n",
      "Step  60700 | Loss: 3.4241 | LR: 1.79e-04 | Speed: 5.6 steps/s\n",
      "Step  60800 | Loss: 4.5145 | LR: 1.79e-04 | Speed: 5.6 steps/s\n",
      "Step  60900 | Loss: 3.8475 | LR: 1.79e-04 | Speed: 5.7 steps/s\n",
      "Step  61000 | Loss: 4.1113 | LR: 1.79e-04 | Speed: 5.7 steps/s\n",
      "Step  61100 | Loss: 3.8578 | LR: 1.79e-04 | Speed: 5.7 steps/s\n",
      "Step  61200 | Loss: 3.7981 | LR: 1.79e-04 | Speed: 5.6 steps/s\n",
      "Step  61300 | Loss: 3.3715 | LR: 1.78e-04 | Speed: 5.6 steps/s\n",
      "Step  61400 | Loss: 3.6777 | LR: 1.78e-04 | Speed: 5.7 steps/s\n",
      "Step  61500 | Loss: 3.7765 | LR: 1.78e-04 | Speed: 5.6 steps/s\n",
      "Step  61600 | Loss: 3.6551 | LR: 1.78e-04 | Speed: 5.5 steps/s\n",
      "Step  61700 | Loss: 4.2876 | LR: 1.78e-04 | Speed: 5.6 steps/s\n",
      "Step  61800 | Loss: 3.9831 | LR: 1.78e-04 | Speed: 5.6 steps/s\n",
      "Step  61900 | Loss: 4.1311 | LR: 1.78e-04 | Speed: 5.6 steps/s\n",
      "Step  62000 | Loss: 3.8913 | LR: 1.77e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.4957\n",
      "Step  62100 | Loss: 4.4284 | LR: 1.77e-04 | Speed: 5.2 steps/s\n",
      "Step  62200 | Loss: 3.8199 | LR: 1.77e-04 | Speed: 5.6 steps/s\n",
      "Step  62300 | Loss: 3.5396 | LR: 1.77e-04 | Speed: 5.6 steps/s\n",
      "Step  62400 | Loss: 4.1168 | LR: 1.77e-04 | Speed: 5.7 steps/s\n",
      "Step  62500 | Loss: 3.7960 | LR: 1.77e-04 | Speed: 4.2 steps/s\n",
      "Step  62600 | Loss: 3.5146 | LR: 1.77e-04 | Speed: 4.8 steps/s\n",
      "Step  62700 | Loss: 4.2766 | LR: 1.76e-04 | Speed: 5.6 steps/s\n",
      "Step  62800 | Loss: 3.9867 | LR: 1.76e-04 | Speed: 5.6 steps/s\n",
      "Step  62900 | Loss: 3.8943 | LR: 1.76e-04 | Speed: 5.6 steps/s\n",
      "Step  63000 | Loss: 3.6442 | LR: 1.76e-04 | Speed: 5.6 steps/s\n",
      "Step  63100 | Loss: 3.9692 | LR: 1.76e-04 | Speed: 5.6 steps/s\n",
      "Step  63200 | Loss: 3.3532 | LR: 1.76e-04 | Speed: 5.7 steps/s\n",
      "Step  63300 | Loss: 3.5537 | LR: 1.76e-04 | Speed: 5.6 steps/s\n",
      "Step  63400 | Loss: 3.7873 | LR: 1.76e-04 | Speed: 5.6 steps/s\n",
      "Step  63500 | Loss: 3.7824 | LR: 1.75e-04 | Speed: 5.6 steps/s\n",
      "Step  63600 | Loss: 4.1772 | LR: 1.75e-04 | Speed: 5.7 steps/s\n",
      "Step  63700 | Loss: 3.8509 | LR: 1.75e-04 | Speed: 5.6 steps/s\n",
      "Step  63800 | Loss: 4.2315 | LR: 1.75e-04 | Speed: 5.7 steps/s\n",
      "Step  63900 | Loss: 3.7229 | LR: 1.75e-04 | Speed: 5.7 steps/s\n",
      "Step  64000 | Loss: 4.0550 | LR: 1.75e-04 | Speed: 5.5 steps/s\n",
      "  >> Validation loss: 4.5106\n",
      "Step  64100 | Loss: 3.9529 | LR: 1.75e-04 | Speed: 5.3 steps/s\n",
      "Step  64200 | Loss: 4.0550 | LR: 1.74e-04 | Speed: 5.6 steps/s\n",
      "Step  64300 | Loss: 3.8903 | LR: 1.74e-04 | Speed: 5.6 steps/s\n",
      "Step  64400 | Loss: 4.1683 | LR: 1.74e-04 | Speed: 5.7 steps/s\n",
      "Step  64500 | Loss: 3.7302 | LR: 1.74e-04 | Speed: 5.6 steps/s\n",
      "Step  64600 | Loss: 3.9862 | LR: 1.74e-04 | Speed: 5.7 steps/s\n",
      "Step  64700 | Loss: 3.3310 | LR: 1.74e-04 | Speed: 5.7 steps/s\n",
      "Step  64800 | Loss: 3.4293 | LR: 1.74e-04 | Speed: 5.6 steps/s\n",
      "Step  64900 | Loss: 3.5865 | LR: 1.73e-04 | Speed: 5.7 steps/s\n",
      "Step  65000 | Loss: 3.6026 | LR: 1.73e-04 | Speed: 5.6 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_65000.pt\n",
      "Step  65100 | Loss: 3.9706 | LR: 1.73e-04 | Speed: 4.3 steps/s\n",
      "Step  65200 | Loss: 4.0894 | LR: 1.73e-04 | Speed: 5.6 steps/s\n",
      "Step  65300 | Loss: 3.1255 | LR: 1.73e-04 | Speed: 5.6 steps/s\n",
      "Step  65400 | Loss: 3.9715 | LR: 1.73e-04 | Speed: 5.7 steps/s\n",
      "Step  65500 | Loss: 4.4112 | LR: 1.73e-04 | Speed: 5.6 steps/s\n",
      "Step  65600 | Loss: 3.9882 | LR: 1.73e-04 | Speed: 5.7 steps/s\n",
      "Step  65700 | Loss: 3.8224 | LR: 1.72e-04 | Speed: 5.6 steps/s\n",
      "Step  65800 | Loss: 3.9120 | LR: 1.72e-04 | Speed: 5.7 steps/s\n",
      "Step  65900 | Loss: 4.1255 | LR: 1.72e-04 | Speed: 5.6 steps/s\n",
      "Step  66000 | Loss: 3.8914 | LR: 1.72e-04 | Speed: 5.5 steps/s\n",
      "  >> Validation loss: 4.4931\n",
      "Step  66100 | Loss: 3.1261 | LR: 1.72e-04 | Speed: 5.2 steps/s\n",
      "Step  66200 | Loss: 3.6859 | LR: 1.72e-04 | Speed: 5.6 steps/s\n",
      "Step  66300 | Loss: 4.1794 | LR: 1.72e-04 | Speed: 5.7 steps/s\n",
      "Step  66400 | Loss: 3.8407 | LR: 1.72e-04 | Speed: 5.7 steps/s\n",
      "Step  66500 | Loss: 3.8507 | LR: 1.71e-04 | Speed: 5.7 steps/s\n",
      "Step  66600 | Loss: 4.1140 | LR: 1.71e-04 | Speed: 5.7 steps/s\n",
      "Step  66700 | Loss: 4.3725 | LR: 1.71e-04 | Speed: 5.6 steps/s\n",
      "Step  66800 | Loss: 4.1563 | LR: 1.71e-04 | Speed: 5.6 steps/s\n",
      "Step  66900 | Loss: 3.7580 | LR: 1.71e-04 | Speed: 5.6 steps/s\n",
      "Step  67000 | Loss: 4.0867 | LR: 1.71e-04 | Speed: 5.6 steps/s\n",
      "Step  67100 | Loss: 3.8508 | LR: 1.71e-04 | Speed: 5.6 steps/s\n",
      "Step  67200 | Loss: 3.6823 | LR: 1.70e-04 | Speed: 5.7 steps/s\n",
      "Step  67300 | Loss: 3.8946 | LR: 1.70e-04 | Speed: 5.6 steps/s\n",
      "Step  67400 | Loss: 3.8497 | LR: 1.70e-04 | Speed: 5.6 steps/s\n",
      "Step  67500 | Loss: 3.9982 | LR: 1.70e-04 | Speed: 5.7 steps/s\n",
      "Step  67600 | Loss: 3.9305 | LR: 1.70e-04 | Speed: 5.7 steps/s\n",
      "Step  67700 | Loss: 3.8591 | LR: 1.70e-04 | Speed: 5.6 steps/s\n",
      "Step  67800 | Loss: 4.2310 | LR: 1.70e-04 | Speed: 5.7 steps/s\n",
      "Step  67900 | Loss: 4.1843 | LR: 1.70e-04 | Speed: 5.6 steps/s\n",
      "Step  68000 | Loss: 4.1292 | LR: 1.69e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4837\n",
      "  >> New best model saved!\n",
      "Step  68100 | Loss: 3.9022 | LR: 1.69e-04 | Speed: 4.5 steps/s\n",
      "Step  68200 | Loss: 4.6396 | LR: 1.69e-04 | Speed: 5.7 steps/s\n",
      "Step  68300 | Loss: 3.7657 | LR: 1.69e-04 | Speed: 5.7 steps/s\n",
      "Step  68400 | Loss: 4.2595 | LR: 1.69e-04 | Speed: 5.6 steps/s\n",
      "Step  68500 | Loss: 3.7524 | LR: 1.69e-04 | Speed: 5.6 steps/s\n",
      "\n",
      "--- Epoch 6 completed ---\n",
      "\n",
      "Step  68600 | Loss: 4.1636 | LR: 1.69e-04 | Speed: 5.3 steps/s\n",
      "Step  68700 | Loss: 3.6926 | LR: 1.69e-04 | Speed: 5.6 steps/s\n",
      "Step  68800 | Loss: 3.6828 | LR: 1.68e-04 | Speed: 5.7 steps/s\n",
      "Step  68900 | Loss: 3.9210 | LR: 1.68e-04 | Speed: 5.6 steps/s\n",
      "Step  69000 | Loss: 3.7204 | LR: 1.68e-04 | Speed: 5.6 steps/s\n",
      "Step  69100 | Loss: 3.2311 | LR: 1.68e-04 | Speed: 5.5 steps/s\n",
      "Step  69200 | Loss: 3.9860 | LR: 1.68e-04 | Speed: 5.6 steps/s\n",
      "Step  69300 | Loss: 3.8670 | LR: 1.68e-04 | Speed: 5.7 steps/s\n",
      "Step  69400 | Loss: 3.7553 | LR: 1.68e-04 | Speed: 5.6 steps/s\n",
      "Step  69500 | Loss: 4.0495 | LR: 1.68e-04 | Speed: 5.6 steps/s\n",
      "Step  69600 | Loss: 4.3963 | LR: 1.68e-04 | Speed: 5.6 steps/s\n",
      "Step  69700 | Loss: 3.6755 | LR: 1.67e-04 | Speed: 5.6 steps/s\n",
      "Step  69800 | Loss: 3.9537 | LR: 1.67e-04 | Speed: 5.5 steps/s\n",
      "Step  69900 | Loss: 3.8598 | LR: 1.67e-04 | Speed: 5.7 steps/s\n",
      "Step  70000 | Loss: 3.7266 | LR: 1.67e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4785\n",
      "  >> New best model saved!\n",
      "  >> Checkpoint saved: checkpoint_step_70000.pt\n",
      "Step  70100 | Loss: 3.8984 | LR: 1.67e-04 | Speed: 3.5 steps/s\n",
      "Step  70200 | Loss: 4.0636 | LR: 1.67e-04 | Speed: 5.6 steps/s\n",
      "Step  70300 | Loss: 3.9891 | LR: 1.67e-04 | Speed: 5.5 steps/s\n",
      "Step  70400 | Loss: 3.9738 | LR: 1.67e-04 | Speed: 5.6 steps/s\n",
      "Step  70500 | Loss: 3.8376 | LR: 1.66e-04 | Speed: 5.7 steps/s\n",
      "Step  70600 | Loss: 3.8070 | LR: 1.66e-04 | Speed: 5.6 steps/s\n",
      "Step  70700 | Loss: 3.9994 | LR: 1.66e-04 | Speed: 5.6 steps/s\n",
      "Step  70800 | Loss: 3.5344 | LR: 1.66e-04 | Speed: 5.7 steps/s\n",
      "Step  70900 | Loss: 3.6310 | LR: 1.66e-04 | Speed: 5.6 steps/s\n",
      "Step  71000 | Loss: 4.0518 | LR: 1.66e-04 | Speed: 5.6 steps/s\n",
      "Step  71100 | Loss: 4.1533 | LR: 1.66e-04 | Speed: 5.6 steps/s\n",
      "Step  71200 | Loss: 4.2295 | LR: 1.66e-04 | Speed: 5.7 steps/s\n",
      "Step  71300 | Loss: 4.4448 | LR: 1.66e-04 | Speed: 5.6 steps/s\n",
      "Step  71400 | Loss: 3.8253 | LR: 1.65e-04 | Speed: 5.6 steps/s\n",
      "Step  71500 | Loss: 3.5067 | LR: 1.65e-04 | Speed: 5.6 steps/s\n",
      "Step  71600 | Loss: 4.1458 | LR: 1.65e-04 | Speed: 5.7 steps/s\n",
      "Step  71700 | Loss: 3.6168 | LR: 1.65e-04 | Speed: 5.6 steps/s\n",
      "Step  71800 | Loss: 3.9996 | LR: 1.65e-04 | Speed: 5.5 steps/s\n",
      "Step  71900 | Loss: 4.2009 | LR: 1.65e-04 | Speed: 5.7 steps/s\n",
      "Step  72000 | Loss: 3.7399 | LR: 1.65e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4819\n",
      "Step  72100 | Loss: 3.6344 | LR: 1.65e-04 | Speed: 5.2 steps/s\n",
      "Step  72200 | Loss: 3.7276 | LR: 1.64e-04 | Speed: 5.6 steps/s\n",
      "Step  72300 | Loss: 3.2556 | LR: 1.64e-04 | Speed: 5.7 steps/s\n",
      "Step  72400 | Loss: 4.5324 | LR: 1.64e-04 | Speed: 5.6 steps/s\n",
      "Step  72500 | Loss: 3.4634 | LR: 1.64e-04 | Speed: 5.5 steps/s\n",
      "Step  72600 | Loss: 3.8931 | LR: 1.64e-04 | Speed: 5.6 steps/s\n",
      "Step  72700 | Loss: 3.7945 | LR: 1.64e-04 | Speed: 5.7 steps/s\n",
      "Step  72800 | Loss: 4.1401 | LR: 1.64e-04 | Speed: 4.9 steps/s\n",
      "Step  72900 | Loss: 3.7908 | LR: 1.64e-04 | Speed: 5.6 steps/s\n",
      "Step  73000 | Loss: 4.1606 | LR: 1.64e-04 | Speed: 5.8 steps/s\n",
      "Step  73100 | Loss: 3.7870 | LR: 1.63e-04 | Speed: 5.7 steps/s\n",
      "Step  73200 | Loss: 3.8944 | LR: 1.63e-04 | Speed: 5.6 steps/s\n",
      "Step  73300 | Loss: 4.4232 | LR: 1.63e-04 | Speed: 5.7 steps/s\n",
      "Step  73400 | Loss: 3.7945 | LR: 1.63e-04 | Speed: 5.6 steps/s\n",
      "Step  73500 | Loss: 3.9838 | LR: 1.63e-04 | Speed: 5.6 steps/s\n",
      "Step  73600 | Loss: 3.8717 | LR: 1.63e-04 | Speed: 5.6 steps/s\n",
      "Step  73700 | Loss: 3.8796 | LR: 1.63e-04 | Speed: 5.7 steps/s\n",
      "Step  73800 | Loss: 3.4120 | LR: 1.63e-04 | Speed: 5.7 steps/s\n",
      "Step  73900 | Loss: 4.1855 | LR: 1.63e-04 | Speed: 5.6 steps/s\n",
      "Step  74000 | Loss: 4.2430 | LR: 1.62e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4697\n",
      "  >> New best model saved!\n",
      "Step  74100 | Loss: 3.6476 | LR: 1.62e-04 | Speed: 4.5 steps/s\n",
      "Step  74200 | Loss: 3.6343 | LR: 1.62e-04 | Speed: 5.5 steps/s\n",
      "Step  74300 | Loss: 3.4661 | LR: 1.62e-04 | Speed: 5.6 steps/s\n",
      "Step  74400 | Loss: 4.1502 | LR: 1.62e-04 | Speed: 5.6 steps/s\n",
      "Step  74500 | Loss: 4.1019 | LR: 1.62e-04 | Speed: 5.7 steps/s\n",
      "Step  74600 | Loss: 3.6218 | LR: 1.62e-04 | Speed: 5.4 steps/s\n",
      "Step  74700 | Loss: 3.8436 | LR: 1.62e-04 | Speed: 5.6 steps/s\n",
      "Step  74800 | Loss: 3.7446 | LR: 1.62e-04 | Speed: 5.7 steps/s\n",
      "Step  74900 | Loss: 3.7372 | LR: 1.61e-04 | Speed: 5.6 steps/s\n",
      "Step  75000 | Loss: 4.2114 | LR: 1.61e-04 | Speed: 5.6 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_75000.pt\n",
      "Step  75100 | Loss: 3.8188 | LR: 1.61e-04 | Speed: 4.2 steps/s\n",
      "Step  75200 | Loss: 4.0697 | LR: 1.61e-04 | Speed: 5.7 steps/s\n",
      "Step  75300 | Loss: 3.7272 | LR: 1.61e-04 | Speed: 5.6 steps/s\n",
      "Step  75400 | Loss: 3.8893 | LR: 1.61e-04 | Speed: 5.7 steps/s\n",
      "Step  75500 | Loss: 4.2181 | LR: 1.61e-04 | Speed: 5.7 steps/s\n",
      "Step  75600 | Loss: 3.8029 | LR: 1.61e-04 | Speed: 5.7 steps/s\n",
      "Step  75700 | Loss: 3.5273 | LR: 1.61e-04 | Speed: 5.8 steps/s\n",
      "Step  75800 | Loss: 4.3036 | LR: 1.61e-04 | Speed: 5.7 steps/s\n",
      "Step  75900 | Loss: 3.3226 | LR: 1.60e-04 | Speed: 5.7 steps/s\n",
      "Step  76000 | Loss: 4.2768 | LR: 1.60e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.4772\n",
      "Step  76100 | Loss: 3.9506 | LR: 1.60e-04 | Speed: 5.2 steps/s\n",
      "Step  76200 | Loss: 3.8541 | LR: 1.60e-04 | Speed: 5.6 steps/s\n",
      "Step  76300 | Loss: 3.6262 | LR: 1.60e-04 | Speed: 5.6 steps/s\n",
      "Step  76400 | Loss: 3.7477 | LR: 1.60e-04 | Speed: 5.6 steps/s\n",
      "Step  76500 | Loss: 3.3712 | LR: 1.60e-04 | Speed: 5.6 steps/s\n",
      "Step  76600 | Loss: 3.9345 | LR: 1.60e-04 | Speed: 5.6 steps/s\n",
      "Step  76700 | Loss: 3.8951 | LR: 1.60e-04 | Speed: 5.6 steps/s\n",
      "Step  76800 | Loss: 3.9346 | LR: 1.59e-04 | Speed: 5.7 steps/s\n",
      "Step  76900 | Loss: 3.6648 | LR: 1.59e-04 | Speed: 5.6 steps/s\n",
      "Step  77000 | Loss: 4.1012 | LR: 1.59e-04 | Speed: 5.6 steps/s\n",
      "Step  77100 | Loss: 3.9984 | LR: 1.59e-04 | Speed: 5.7 steps/s\n",
      "Step  77200 | Loss: 3.9445 | LR: 1.59e-04 | Speed: 5.7 steps/s\n",
      "Step  77300 | Loss: 3.6217 | LR: 1.59e-04 | Speed: 5.6 steps/s\n",
      "Step  77400 | Loss: 4.0276 | LR: 1.59e-04 | Speed: 5.6 steps/s\n",
      "Step  77500 | Loss: 4.0786 | LR: 1.59e-04 | Speed: 5.6 steps/s\n",
      "Step  77600 | Loss: 3.9589 | LR: 1.59e-04 | Speed: 5.5 steps/s\n",
      "Step  77700 | Loss: 4.0689 | LR: 1.59e-04 | Speed: 5.6 steps/s\n",
      "Step  77800 | Loss: 3.7318 | LR: 1.58e-04 | Speed: 5.7 steps/s\n",
      "Step  77900 | Loss: 3.6732 | LR: 1.58e-04 | Speed: 5.3 steps/s\n",
      "Step  78000 | Loss: 4.3361 | LR: 1.58e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.4621\n",
      "  >> New best model saved!\n",
      "Step  78100 | Loss: 3.5715 | LR: 1.58e-04 | Speed: 4.5 steps/s\n",
      "Step  78200 | Loss: 3.9486 | LR: 1.58e-04 | Speed: 5.7 steps/s\n",
      "Step  78300 | Loss: 3.2597 | LR: 1.58e-04 | Speed: 5.7 steps/s\n",
      "Step  78400 | Loss: 3.2767 | LR: 1.58e-04 | Speed: 5.7 steps/s\n",
      "Step  78500 | Loss: 3.4576 | LR: 1.58e-04 | Speed: 5.7 steps/s\n",
      "Step  78600 | Loss: 3.7822 | LR: 1.58e-04 | Speed: 5.5 steps/s\n",
      "Step  78700 | Loss: 4.5569 | LR: 1.58e-04 | Speed: 5.6 steps/s\n",
      "Step  78800 | Loss: 4.1983 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step  78900 | Loss: 3.7289 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step  79000 | Loss: 3.9411 | LR: 1.57e-04 | Speed: 5.7 steps/s\n",
      "Step  79100 | Loss: 3.7393 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step  79200 | Loss: 4.0890 | LR: 1.57e-04 | Speed: 5.7 steps/s\n",
      "Step  79300 | Loss: 3.4369 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step  79400 | Loss: 3.4309 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step  79500 | Loss: 3.9757 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step  79600 | Loss: 3.7133 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step  79700 | Loss: 4.2808 | LR: 1.57e-04 | Speed: 5.6 steps/s\n",
      "Step  79800 | Loss: 4.0004 | LR: 1.56e-04 | Speed: 5.7 steps/s\n",
      "Step  79900 | Loss: 3.6815 | LR: 1.56e-04 | Speed: 5.7 steps/s\n",
      "Step  80000 | Loss: 3.9019 | LR: 1.56e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4691\n",
      "  >> Checkpoint saved: checkpoint_step_80000.pt\n",
      "\n",
      "--- Epoch 7 completed ---\n",
      "\n",
      "Step  80100 | Loss: 4.2655 | LR: 1.56e-04 | Speed: 3.8 steps/s\n",
      "Step  80200 | Loss: 3.7043 | LR: 1.56e-04 | Speed: 5.6 steps/s\n",
      "Step  80300 | Loss: 4.1442 | LR: 1.56e-04 | Speed: 5.6 steps/s\n",
      "Step  80400 | Loss: 3.5844 | LR: 1.56e-04 | Speed: 5.6 steps/s\n",
      "Step  80500 | Loss: 3.8782 | LR: 1.56e-04 | Speed: 5.6 steps/s\n",
      "Step  80600 | Loss: 4.2901 | LR: 1.56e-04 | Speed: 5.7 steps/s\n",
      "Step  80700 | Loss: 3.5703 | LR: 1.56e-04 | Speed: 5.6 steps/s\n",
      "Step  80800 | Loss: 3.7861 | LR: 1.55e-04 | Speed: 5.5 steps/s\n",
      "Step  80900 | Loss: 3.7115 | LR: 1.55e-04 | Speed: 5.6 steps/s\n",
      "Step  81000 | Loss: 3.6411 | LR: 1.55e-04 | Speed: 5.6 steps/s\n",
      "Step  81100 | Loss: 4.2133 | LR: 1.55e-04 | Speed: 5.7 steps/s\n",
      "Step  81200 | Loss: 4.1285 | LR: 1.55e-04 | Speed: 5.7 steps/s\n",
      "Step  81300 | Loss: 3.5841 | LR: 1.55e-04 | Speed: 5.7 steps/s\n",
      "Step  81400 | Loss: 3.9154 | LR: 1.55e-04 | Speed: 5.7 steps/s\n",
      "Step  81500 | Loss: 3.8646 | LR: 1.55e-04 | Speed: 5.6 steps/s\n",
      "Step  81600 | Loss: 4.1792 | LR: 1.55e-04 | Speed: 5.6 steps/s\n",
      "Step  81700 | Loss: 4.0064 | LR: 1.55e-04 | Speed: 5.7 steps/s\n",
      "Step  81800 | Loss: 3.7031 | LR: 1.55e-04 | Speed: 5.6 steps/s\n",
      "Step  81900 | Loss: 3.8934 | LR: 1.54e-04 | Speed: 5.5 steps/s\n",
      "Step  82000 | Loss: 3.9279 | LR: 1.54e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.4401\n",
      "  >> New best model saved!\n",
      "Step  82100 | Loss: 3.5300 | LR: 1.54e-04 | Speed: 4.5 steps/s\n",
      "Step  82200 | Loss: 4.1000 | LR: 1.54e-04 | Speed: 5.6 steps/s\n",
      "Step  82300 | Loss: 3.7275 | LR: 1.54e-04 | Speed: 5.6 steps/s\n",
      "Step  82400 | Loss: 3.5728 | LR: 1.54e-04 | Speed: 5.6 steps/s\n",
      "Step  82500 | Loss: 3.5028 | LR: 1.54e-04 | Speed: 5.6 steps/s\n",
      "Step  82600 | Loss: 4.3694 | LR: 1.54e-04 | Speed: 5.6 steps/s\n",
      "Step  82700 | Loss: 3.6830 | LR: 1.54e-04 | Speed: 5.7 steps/s\n",
      "Step  82800 | Loss: 3.9978 | LR: 1.54e-04 | Speed: 5.3 steps/s\n",
      "Step  82900 | Loss: 3.9786 | LR: 1.53e-04 | Speed: 5.6 steps/s\n",
      "Step  83000 | Loss: 3.9811 | LR: 1.53e-04 | Speed: 5.6 steps/s\n",
      "Step  83100 | Loss: 3.4649 | LR: 1.53e-04 | Speed: 5.6 steps/s\n",
      "Step  83200 | Loss: 3.9942 | LR: 1.53e-04 | Speed: 4.9 steps/s\n",
      "Step  83300 | Loss: 4.3225 | LR: 1.53e-04 | Speed: 5.6 steps/s\n",
      "Step  83400 | Loss: 4.3042 | LR: 1.53e-04 | Speed: 5.6 steps/s\n",
      "Step  83500 | Loss: 3.6460 | LR: 1.53e-04 | Speed: 5.6 steps/s\n",
      "Step  83600 | Loss: 4.1800 | LR: 1.53e-04 | Speed: 5.6 steps/s\n",
      "Step  83700 | Loss: 4.0119 | LR: 1.53e-04 | Speed: 5.5 steps/s\n",
      "Step  83800 | Loss: 3.5274 | LR: 1.53e-04 | Speed: 5.7 steps/s\n",
      "Step  83900 | Loss: 4.0912 | LR: 1.53e-04 | Speed: 5.7 steps/s\n",
      "Step  84000 | Loss: 3.8726 | LR: 1.52e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4617\n",
      "Step  84100 | Loss: 3.6556 | LR: 1.52e-04 | Speed: 5.2 steps/s\n",
      "Step  84200 | Loss: 3.6383 | LR: 1.52e-04 | Speed: 5.6 steps/s\n",
      "Step  84300 | Loss: 4.4610 | LR: 1.52e-04 | Speed: 5.6 steps/s\n",
      "Step  84400 | Loss: 4.0725 | LR: 1.52e-04 | Speed: 5.6 steps/s\n",
      "Step  84500 | Loss: 4.3588 | LR: 1.52e-04 | Speed: 5.6 steps/s\n",
      "Step  84600 | Loss: 4.1454 | LR: 1.52e-04 | Speed: 5.7 steps/s\n",
      "Step  84700 | Loss: 3.9308 | LR: 1.52e-04 | Speed: 5.6 steps/s\n",
      "Step  84800 | Loss: 3.8165 | LR: 1.52e-04 | Speed: 5.6 steps/s\n",
      "Step  84900 | Loss: 3.7525 | LR: 1.52e-04 | Speed: 5.7 steps/s\n",
      "Step  85000 | Loss: 3.5247 | LR: 1.52e-04 | Speed: 5.7 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_85000.pt\n",
      "Step  85100 | Loss: 3.6069 | LR: 1.51e-04 | Speed: 4.2 steps/s\n",
      "Step  85200 | Loss: 3.7616 | LR: 1.51e-04 | Speed: 5.6 steps/s\n",
      "Step  85300 | Loss: 3.9612 | LR: 1.51e-04 | Speed: 5.6 steps/s\n",
      "Step  85400 | Loss: 4.3915 | LR: 1.51e-04 | Speed: 5.6 steps/s\n",
      "Step  85500 | Loss: 3.9802 | LR: 1.51e-04 | Speed: 5.7 steps/s\n",
      "Step  85600 | Loss: 3.7154 | LR: 1.51e-04 | Speed: 5.7 steps/s\n",
      "Step  85700 | Loss: 4.0552 | LR: 1.51e-04 | Speed: 5.7 steps/s\n",
      "Step  85800 | Loss: 3.7302 | LR: 1.51e-04 | Speed: 5.7 steps/s\n",
      "Step  85900 | Loss: 3.5982 | LR: 1.51e-04 | Speed: 5.7 steps/s\n",
      "Step  86000 | Loss: 3.8402 | LR: 1.51e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4504\n",
      "Step  86100 | Loss: 3.9561 | LR: 1.51e-04 | Speed: 5.2 steps/s\n",
      "Step  86200 | Loss: 3.6499 | LR: 1.51e-04 | Speed: 5.7 steps/s\n",
      "Step  86300 | Loss: 3.8017 | LR: 1.50e-04 | Speed: 5.7 steps/s\n",
      "Step  86400 | Loss: 4.0387 | LR: 1.50e-04 | Speed: 5.6 steps/s\n",
      "Step  86500 | Loss: 3.9834 | LR: 1.50e-04 | Speed: 5.7 steps/s\n",
      "Step  86600 | Loss: 3.7006 | LR: 1.50e-04 | Speed: 5.6 steps/s\n",
      "Step  86700 | Loss: 3.9415 | LR: 1.50e-04 | Speed: 5.7 steps/s\n",
      "Step  86800 | Loss: 3.4532 | LR: 1.50e-04 | Speed: 5.6 steps/s\n",
      "Step  86900 | Loss: 3.4012 | LR: 1.50e-04 | Speed: 5.7 steps/s\n",
      "Step  87000 | Loss: 3.4297 | LR: 1.50e-04 | Speed: 5.6 steps/s\n",
      "Step  87100 | Loss: 3.9620 | LR: 1.50e-04 | Speed: 5.6 steps/s\n",
      "Step  87200 | Loss: 4.1253 | LR: 1.50e-04 | Speed: 5.7 steps/s\n",
      "Step  87300 | Loss: 3.8818 | LR: 1.50e-04 | Speed: 5.6 steps/s\n",
      "Step  87400 | Loss: 4.0268 | LR: 1.49e-04 | Speed: 5.6 steps/s\n",
      "Step  87500 | Loss: 3.9468 | LR: 1.49e-04 | Speed: 5.6 steps/s\n",
      "Step  87600 | Loss: 3.3901 | LR: 1.49e-04 | Speed: 5.5 steps/s\n",
      "Step  87700 | Loss: 4.2812 | LR: 1.49e-04 | Speed: 5.6 steps/s\n",
      "Step  87800 | Loss: 3.9351 | LR: 1.49e-04 | Speed: 5.7 steps/s\n",
      "Step  87900 | Loss: 3.5476 | LR: 1.49e-04 | Speed: 5.7 steps/s\n",
      "Step  88000 | Loss: 3.9906 | LR: 1.49e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.4681\n",
      "Step  88100 | Loss: 3.8659 | LR: 1.49e-04 | Speed: 5.2 steps/s\n",
      "Step  88200 | Loss: 4.2623 | LR: 1.49e-04 | Speed: 5.7 steps/s\n",
      "Step  88300 | Loss: 3.8383 | LR: 1.49e-04 | Speed: 5.6 steps/s\n",
      "Step  88400 | Loss: 4.3632 | LR: 1.49e-04 | Speed: 5.6 steps/s\n",
      "Step  88500 | Loss: 4.0456 | LR: 1.49e-04 | Speed: 5.7 steps/s\n",
      "Step  88600 | Loss: 3.8912 | LR: 1.48e-04 | Speed: 5.7 steps/s\n",
      "Step  88700 | Loss: 4.0403 | LR: 1.48e-04 | Speed: 5.7 steps/s\n",
      "Step  88800 | Loss: 3.4171 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  88900 | Loss: 3.8859 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  89000 | Loss: 4.6359 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  89100 | Loss: 3.8710 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  89200 | Loss: 3.2683 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  89300 | Loss: 4.0019 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  89400 | Loss: 3.9296 | LR: 1.48e-04 | Speed: 5.7 steps/s\n",
      "Step  89500 | Loss: 3.7034 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  89600 | Loss: 3.5049 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  89700 | Loss: 4.1571 | LR: 1.48e-04 | Speed: 5.6 steps/s\n",
      "Step  89800 | Loss: 4.1606 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  89900 | Loss: 4.2935 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  90000 | Loss: 3.1492 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4634\n",
      "  >> Checkpoint saved: checkpoint_step_90000.pt\n",
      "Step  90100 | Loss: 3.7764 | LR: 1.47e-04 | Speed: 4.0 steps/s\n",
      "Step  90200 | Loss: 4.2089 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  90300 | Loss: 3.6123 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  90400 | Loss: 4.0277 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  90500 | Loss: 3.4596 | LR: 1.47e-04 | Speed: 5.7 steps/s\n",
      "Step  90600 | Loss: 3.5283 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  90700 | Loss: 3.7823 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  90800 | Loss: 3.7358 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  90900 | Loss: 3.8409 | LR: 1.47e-04 | Speed: 5.6 steps/s\n",
      "Step  91000 | Loss: 4.0209 | LR: 1.47e-04 | Speed: 5.7 steps/s\n",
      "Step  91100 | Loss: 4.1665 | LR: 1.46e-04 | Speed: 5.6 steps/s\n",
      "Step  91200 | Loss: 3.4911 | LR: 1.46e-04 | Speed: 5.6 steps/s\n",
      "Step  91300 | Loss: 3.8552 | LR: 1.46e-04 | Speed: 5.6 steps/s\n",
      "Step  91400 | Loss: 3.9805 | LR: 1.46e-04 | Speed: 5.6 steps/s\n",
      "\n",
      "--- Epoch 8 completed ---\n",
      "\n",
      "Step  91500 | Loss: 3.4912 | LR: 1.46e-04 | Speed: 5.3 steps/s\n",
      "Step  91600 | Loss: 4.0437 | LR: 1.46e-04 | Speed: 5.6 steps/s\n",
      "Step  91700 | Loss: 4.6244 | LR: 1.46e-04 | Speed: 5.6 steps/s\n",
      "Step  91800 | Loss: 3.5532 | LR: 1.46e-04 | Speed: 5.5 steps/s\n",
      "Step  91900 | Loss: 3.7876 | LR: 1.46e-04 | Speed: 5.5 steps/s\n",
      "Step  92000 | Loss: 4.5382 | LR: 1.46e-04 | Speed: 5.5 steps/s\n",
      "  >> Validation loss: 4.4460\n",
      "Step  92100 | Loss: 3.8299 | LR: 1.46e-04 | Speed: 5.2 steps/s\n",
      "Step  92200 | Loss: 3.7791 | LR: 1.46e-04 | Speed: 5.6 steps/s\n",
      "Step  92300 | Loss: 3.6286 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  92400 | Loss: 4.0170 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  92500 | Loss: 3.7452 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  92600 | Loss: 3.9060 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  92700 | Loss: 3.5010 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  92800 | Loss: 3.7087 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  92900 | Loss: 3.5560 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  93000 | Loss: 4.3219 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  93100 | Loss: 4.1501 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  93200 | Loss: 3.9099 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  93300 | Loss: 4.0892 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  93400 | Loss: 3.3971 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  93500 | Loss: 3.6553 | LR: 1.45e-04 | Speed: 5.6 steps/s\n",
      "Step  93600 | Loss: 4.1174 | LR: 1.44e-04 | Speed: 5.7 steps/s\n",
      "Step  93700 | Loss: 3.6691 | LR: 1.44e-04 | Speed: 5.6 steps/s\n",
      "Step  93800 | Loss: 4.0417 | LR: 1.44e-04 | Speed: 4.6 steps/s\n",
      "Step  93900 | Loss: 3.9884 | LR: 1.44e-04 | Speed: 5.6 steps/s\n",
      "Step  94000 | Loss: 3.4022 | LR: 1.44e-04 | Speed: 5.7 steps/s\n",
      "  >> Validation loss: 4.4689\n",
      "Step  94100 | Loss: 3.5389 | LR: 1.44e-04 | Speed: 5.2 steps/s\n",
      "Step  94200 | Loss: 3.9029 | LR: 1.44e-04 | Speed: 5.6 steps/s\n",
      "Step  94300 | Loss: 3.4130 | LR: 1.44e-04 | Speed: 5.6 steps/s\n",
      "Step  94400 | Loss: 4.0340 | LR: 1.44e-04 | Speed: 5.6 steps/s\n",
      "Step  94500 | Loss: 3.9566 | LR: 1.44e-04 | Speed: 5.6 steps/s\n",
      "Step  94600 | Loss: 3.9905 | LR: 1.44e-04 | Speed: 5.6 steps/s\n",
      "Step  94700 | Loss: 4.0703 | LR: 1.44e-04 | Speed: 5.7 steps/s\n",
      "Step  94800 | Loss: 3.8353 | LR: 1.44e-04 | Speed: 5.6 steps/s\n",
      "Step  94900 | Loss: 3.7285 | LR: 1.43e-04 | Speed: 5.6 steps/s\n",
      "Step  95000 | Loss: 3.6311 | LR: 1.43e-04 | Speed: 5.6 steps/s\n",
      "  >> Checkpoint saved: checkpoint_step_95000.pt\n",
      "Step  95100 | Loss: 3.5189 | LR: 1.43e-04 | Speed: 4.6 steps/s\n",
      "Step  95200 | Loss: 4.1382 | LR: 1.43e-04 | Speed: 5.6 steps/s\n",
      "Step  95300 | Loss: 4.1333 | LR: 1.43e-04 | Speed: 5.7 steps/s\n",
      "Step  95400 | Loss: 3.8031 | LR: 1.43e-04 | Speed: 5.6 steps/s\n",
      "Step  95500 | Loss: 3.4603 | LR: 1.43e-04 | Speed: 5.7 steps/s\n",
      "Step  95600 | Loss: 3.6693 | LR: 1.43e-04 | Speed: 5.8 steps/s\n",
      "Step  95700 | Loss: 3.8966 | LR: 1.43e-04 | Speed: 5.6 steps/s\n",
      "Step  95800 | Loss: 4.1965 | LR: 1.43e-04 | Speed: 5.7 steps/s\n",
      "Step  95900 | Loss: 4.3334 | LR: 1.43e-04 | Speed: 5.6 steps/s\n",
      "Step  96000 | Loss: 3.5641 | LR: 1.43e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4378\n",
      "  >> New best model saved!\n",
      "Step  96100 | Loss: 3.8814 | LR: 1.43e-04 | Speed: 4.6 steps/s\n",
      "Step  96200 | Loss: 3.8393 | LR: 1.42e-04 | Speed: 5.6 steps/s\n",
      "Step  96300 | Loss: 3.6751 | LR: 1.42e-04 | Speed: 5.7 steps/s\n",
      "Step  96400 | Loss: 3.7471 | LR: 1.42e-04 | Speed: 5.6 steps/s\n",
      "Step  96500 | Loss: 3.9194 | LR: 1.42e-04 | Speed: 5.6 steps/s\n",
      "Step  96600 | Loss: 3.8962 | LR: 1.42e-04 | Speed: 5.6 steps/s\n",
      "Step  96700 | Loss: 3.9964 | LR: 1.42e-04 | Speed: 5.6 steps/s\n",
      "Step  96800 | Loss: 3.4611 | LR: 1.42e-04 | Speed: 5.7 steps/s\n",
      "Step  96900 | Loss: 4.1840 | LR: 1.42e-04 | Speed: 5.6 steps/s\n",
      "Step  97000 | Loss: 3.4025 | LR: 1.42e-04 | Speed: 5.8 steps/s\n",
      "Step  97100 | Loss: 3.2960 | LR: 1.42e-04 | Speed: 5.5 steps/s\n",
      "Step  97200 | Loss: 3.6403 | LR: 1.42e-04 | Speed: 5.7 steps/s\n",
      "Step  97300 | Loss: 3.9196 | LR: 1.42e-04 | Speed: 5.6 steps/s\n",
      "Step  97400 | Loss: 4.4615 | LR: 1.42e-04 | Speed: 5.5 steps/s\n",
      "Step  97500 | Loss: 3.8074 | LR: 1.42e-04 | Speed: 5.6 steps/s\n",
      "Step  97600 | Loss: 4.0709 | LR: 1.41e-04 | Speed: 5.5 steps/s\n",
      "Step  97700 | Loss: 3.9190 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  97800 | Loss: 4.1901 | LR: 1.41e-04 | Speed: 5.5 steps/s\n",
      "Step  97900 | Loss: 3.9957 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  98000 | Loss: 3.5354 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "  >> Validation loss: 4.4443\n",
      "Step  98100 | Loss: 3.9611 | LR: 1.41e-04 | Speed: 5.2 steps/s\n",
      "Step  98200 | Loss: 3.4829 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  98300 | Loss: 4.0847 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  98400 | Loss: 3.4829 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  98500 | Loss: 3.7594 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  98600 | Loss: 3.5895 | LR: 1.41e-04 | Speed: 5.7 steps/s\n",
      "Step  98700 | Loss: 3.9191 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  98800 | Loss: 4.1779 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  98900 | Loss: 3.9029 | LR: 1.41e-04 | Speed: 5.6 steps/s\n",
      "Step  99000 | Loss: 3.8316 | LR: 1.40e-04 | Speed: 5.7 steps/s\n",
      "Step  99100 | Loss: 4.2882 | LR: 1.40e-04 | Speed: 5.6 steps/s\n",
      "Step  99200 | Loss: 3.6553 | LR: 1.40e-04 | Speed: 5.6 steps/s\n",
      "Step  99300 | Loss: 3.8654 | LR: 1.40e-04 | Speed: 5.6 steps/s\n",
      "Step  99400 | Loss: 3.8294 | LR: 1.40e-04 | Speed: 5.6 steps/s\n",
      "Step  99500 | Loss: 3.8293 | LR: 1.40e-04 | Speed: 5.6 steps/s\n",
      "Step  99600 | Loss: 3.4211 | LR: 1.40e-04 | Speed: 5.5 steps/s\n",
      "Step  99700 | Loss: 3.0277 | LR: 1.40e-04 | Speed: 5.6 steps/s\n",
      "Step  99800 | Loss: 3.8231 | LR: 1.40e-04 | Speed: 5.5 steps/s\n",
      "Step  99900 | Loss: 3.8543 | LR: 1.40e-04 | Speed: 5.6 steps/s\n",
      "Step 100000 | Loss: 4.1571 | LR: 1.40e-04 | Speed: 5.5 steps/s\n",
      "  >> Validation loss: 4.4300\n",
      "  >> New best model saved!\n",
      "  >> Checkpoint saved: checkpoint_step_100000.pt\n",
      "\n",
      "--- Epoch 9 completed ---\n",
      "\n",
      "======================================================================\n",
      "Training completed!\n",
      "Total steps: 100,000\n",
      "Total time: 5.03 hours\n",
      "Best validation loss: 4.4300\n",
      "======================================================================\n",
      "Final model saved to ../checkpoints/wmt14_base/final_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "print(\"=\"*70)\n",
    "print(f\"Starting training for {CONFIG['max_steps']:,} steps\")\n",
    "print(f\"Gradient accumulation: {CONFIG['gradient_accumulation_steps']} steps\")\n",
    "print(f\"Effective batch size: ~{CONFIG['max_tokens_per_batch'] * CONFIG['gradient_accumulation_steps']:,} tokens\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "\n",
    "accumulation_loss = 0.0\n",
    "accumulation_steps = 0\n",
    "start_time = time.time()\n",
    "log_start_time = time.time()\n",
    "\n",
    "epoch = 0\n",
    "while global_step < CONFIG[\"max_steps\"]:\n",
    "    epoch += 1\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        if global_step >= CONFIG[\"max_steps\"]:\n",
    "            break\n",
    "        \n",
    "        # Forward and backward\n",
    "        loss = train_step(model, batch, criterion, device)\n",
    "        loss = loss / CONFIG[\"gradient_accumulation_steps\"]\n",
    "        loss.backward()\n",
    "        \n",
    "        accumulation_loss += loss.item()\n",
    "        accumulation_steps += 1\n",
    "        \n",
    "        # Update weights after accumulation\n",
    "        if accumulation_steps >= CONFIG[\"gradient_accumulation_steps\"]:\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG[\"max_grad_norm\"])\n",
    "            \n",
    "            # Optimizer step\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            global_step += 1\n",
    "            \n",
    "            # Logging\n",
    "            if global_step % CONFIG[\"log_steps\"] == 0:\n",
    "                elapsed = time.time() - log_start_time\n",
    "                steps_per_sec = CONFIG[\"log_steps\"] / elapsed\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                \n",
    "                print(f\"Step {global_step:6d} | \"\n",
    "                      f\"Loss: {accumulation_loss:.4f} | \"\n",
    "                      f\"LR: {current_lr:.2e} | \"\n",
    "                      f\"Speed: {steps_per_sec:.1f} steps/s\")\n",
    "                \n",
    "                training_history.append({\n",
    "                    'step': global_step,\n",
    "                    'loss': accumulation_loss,\n",
    "                    'lr': current_lr,\n",
    "                })\n",
    "                \n",
    "                log_start_time = time.time()\n",
    "            \n",
    "            # Evaluation\n",
    "            if global_step % CONFIG[\"eval_steps\"] == 0:\n",
    "                val_loss = evaluate(model, val_loader, criterion, device)\n",
    "                print(f\"  >> Validation loss: {val_loss:.4f}\")\n",
    "                \n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    best_path = Path(CONFIG[\"checkpoint_dir\"]) / \"best_model.pt\"\n",
    "                    save_checkpoint(model, optimizer, scheduler, global_step, val_loss, best_path)\n",
    "                    print(f\"  >> New best model saved!\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if global_step % CONFIG[\"save_steps\"] == 0:\n",
    "                ckpt_path = Path(CONFIG[\"checkpoint_dir\"]) / f\"checkpoint_step_{global_step}.pt\"\n",
    "                save_checkpoint(model, optimizer, scheduler, global_step, accumulation_loss, ckpt_path)\n",
    "                \n",
    "                # Also save as latest\n",
    "                save_checkpoint(model, optimizer, scheduler, global_step, accumulation_loss, resume_path)\n",
    "                print(f\"  >> Checkpoint saved: {ckpt_path.name}\")\n",
    "            \n",
    "            # Reset accumulation\n",
    "            accumulation_loss = 0.0\n",
    "            accumulation_steps = 0\n",
    "    \n",
    "    print(f\"\\n--- Epoch {epoch} completed ---\\n\")\n",
    "\n",
    "# Final save\n",
    "total_time = time.time() - start_time\n",
    "print(\"=\"*70)\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Total steps: {global_step:,}\")\n",
    "print(f\"Total time: {total_time/3600:.2f} hours\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save final model\n",
    "final_path = Path(CONFIG[\"checkpoint_dir\"]) / \"final_model.pt\"\n",
    "save_checkpoint(model, optimizer, scheduler, global_step, accumulation_loss, final_path)\n",
    "print(f\"Final model saved to {final_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 8. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Summary:\n",
      "  Initial loss: 9.9215\n",
      "  Final loss: 4.1571\n",
      "  Min loss: 2.9179 (step 45500)\n",
      "  Best val loss: 4.4300\n",
      "\n",
      "Loss curve (sampled):\n",
      "  Step    100: ███████████████████████████████████████ 9.9215\n",
      "  Step   5100: ███████████ 5.2867\n",
      "  Step  10100: ███████ 4.7566\n",
      "  Step  15100: ██ 3.9555\n",
      "  Step  20100: ██████ 4.5271\n",
      "  Step  25100: ██████ 4.5078\n",
      "  Step  30100: █ 3.7335\n",
      "  Step  35100: ██████ 4.5115\n",
      "  Step  40100: ███████ 4.6572\n",
      "  Step  45100: ████ 4.2267\n",
      "  Step  50100: ██ 3.9495\n",
      "  Step  55100: █ 3.7280\n",
      "  Step  60100:  3.6657\n",
      "  Step  65100: ██ 3.9706\n",
      "  Step  70100: ██ 3.8984\n",
      "  Step  75100: █ 3.8188\n",
      "  Step  80100: ████ 4.2655\n",
      "  Step  85100:  3.6069\n",
      "  Step  90100: █ 3.7764\n",
      "  Step  95100:  3.5189\n"
     ]
    }
   ],
   "source": [
    "# Plot training loss\n",
    "if training_history:\n",
    "    steps = [h['step'] for h in training_history]\n",
    "    losses = [h['loss'] for h in training_history]\n",
    "    lrs = [h['lr'] for h in training_history]\n",
    "    \n",
    "    print(\"Training Summary:\")\n",
    "    print(f\"  Initial loss: {losses[0]:.4f}\")\n",
    "    print(f\"  Final loss: {losses[-1]:.4f}\")\n",
    "    print(f\"  Min loss: {min(losses):.4f} (step {steps[losses.index(min(losses))]})\")\n",
    "    print(f\"  Best val loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "    # Simple ASCII visualization\n",
    "    print(\"\\nLoss curve (sampled):\")\n",
    "    sample_indices = range(0, len(losses), max(1, len(losses)//20))\n",
    "    max_loss = max(losses[i] for i in sample_indices)\n",
    "    min_loss = min(losses[i] for i in sample_indices)\n",
    "    \n",
    "    for i in sample_indices:\n",
    "        normalized = (losses[i] - min_loss) / (max_loss - min_loss + 1e-8)\n",
    "        bar = '█' * int(normalized * 40)\n",
    "        print(f\"  Step {steps[i]:6d}: {bar} {losses[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 9. Quick Translation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation test:\n",
      "======================================================================\n",
      "\n",
      "EN: The weather is nice today.\n",
      "DE: Heute ist das Wetter schön.\n",
      "\n",
      "EN: I love machine learning.\n",
      "DE: Ich liebe die Arbeit.\n",
      "\n",
      "EN: The European Union is an economic and political union.\n",
      "DE: Die Europäische Union ist eine wirtschaftliche und politische Union.\n"
     ]
    }
   ],
   "source": [
    "# Test translation\n",
    "model.eval()\n",
    "\n",
    "test_sentences = [\n",
    "    \"The weather is nice today.\",\n",
    "    \"I love machine learning.\",\n",
    "    \"The European Union is an economic and political union.\",\n",
    "]\n",
    "\n",
    "print(\"Translation test:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for sent in test_sentences:\n",
    "    # Encode\n",
    "    src_ids = tokenizer.encode(sent, add_bos=True, add_eos=True)\n",
    "    src_tensor = torch.tensor([src_ids], device=device)\n",
    "    \n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            src=src_tensor,\n",
    "            max_len=100,\n",
    "            start_token=tokenizer.bos_id,\n",
    "            end_token=tokenizer.eos_id,\n",
    "        )\n",
    "    \n",
    "    # Decode\n",
    "    translation = tokenizer.decode(output[0].tolist(), skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"\\nEN: {sent}\")\n",
    "    print(f\"DE: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook trained a base Transformer model on WMT14 English-German:\n",
    "\n",
    "1. **Dataset**: WMT14 EN-DE (~4.5M sentence pairs)\n",
    "2. **Tokenizer**: BPE with 37K shared vocabulary\n",
    "3. **Model**: Base Transformer (65M parameters)\n",
    "   - d_model=512, n_heads=8, n_layers=6, d_ff=2048\n",
    "4. **Training**: Dynamic batching, gradient accumulation, label smoothing\n",
    "\n",
    "### Checkpoints saved:\n",
    "- `checkpoints/wmt14_base/best_model.pt` - Best validation loss\n",
    "- `checkpoints/wmt14_base/final_model.pt` - Final model\n",
    "- `checkpoints/wmt14_base/tokenizer.model` - BPE tokenizer\n",
    "\n",
    "### Next steps:\n",
    "- Use `04_wmt14_inference.ipynb` to run inference and evaluate BLEU scores\n",
    "- Implement beam search for better translation quality\n",
    "- Train longer for better results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
